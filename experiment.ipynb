{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/eval/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Resolving data files: 100%|██████████| 144/144 [00:02<00:00, 50.37it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"bigcode/the-stack-dedup\", data_dir=\"data/python\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/eval/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:11<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# pip install -q transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"bigcode/starcoder\"\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of batch 0-128\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "tokenizer.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "batch_size = 128\n",
    "prefix_size = 50\n",
    "\n",
    "begin = len(df)-df.prediction_50.isna().sum()\n",
    "\n",
    "while begin < len(df):\n",
    "    end = begin + batch_size\n",
    "    print(f\"Starting processing of batch {begin}-{end-1}\")\n",
    "    batch = list(df.iloc[begin:end][\"content\"].values)\n",
    "    inputs = tokenizer(batch, return_tensors=\"pt\", padding=True).to(device)    \n",
    "    inputs = inputs[\"input_ids\"][:,:prefix_size] # Only keep first tokens\n",
    "\n",
    "    output = model.generate(inputs, max_new_tokens=512,\n",
    "                            do_sample=False,\n",
    "                            )\n",
    "\n",
    "    block_df = df.iloc[begin:end].copy()\n",
    "    block_df[\"prediction_50\"] = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    block_df[\"prefix_50\"] = tokenizer.batch_decode(inputs, skip_special_tokens=True)\n",
    "\n",
    "    block_df[\"bleu_50\"] = block_df.apply(lambda row: \n",
    "                                    bleu.compute(predictions=[row[\"prediction_50\"]],\n",
    "                                                    references=[row[\"content\"]])[\"bleu\"], axis=1)\n",
    "\n",
    "    df.loc[begin:(end-1)] = block_df\n",
    "    df.to_csv(\"samples.csv\", index=False)\n",
    "    begin += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hexsha</th>\n",
       "      <th>size</th>\n",
       "      <th>content</th>\n",
       "      <th>prediction_50</th>\n",
       "      <th>prefix_50</th>\n",
       "      <th>bleu_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d99a20277c32bb1e28312f42ab6d732f38323169</td>\n",
       "      <td>241</td>\n",
       "      <td>from django.contrib import admin\\nfrom .models...</td>\n",
       "      <td>from django.contrib import admin\\nfrom.models ...</td>\n",
       "      <td>from django.contrib import admin\\nfrom.models ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d99e8a9a95f28da6c2d4d1ee42e95a270ab08977</td>\n",
       "      <td>421</td>\n",
       "      <td>class Solution:\\n    def finalPrices(self, pri...</td>\n",
       "      <td>class Solution:\\n    def finalPrices(self, pri...</td>\n",
       "      <td>class Solution:\\n    def finalPrices(self, pri...</td>\n",
       "      <td>0.803812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d99f875863138f11af1d76f0c753c198ad6d96bd</td>\n",
       "      <td>1329</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...</td>\n",
       "      <td>0.169206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d9a6621d903359b14c87695eb4a1ac8dcea18138</td>\n",
       "      <td>844</td>\n",
       "      <td>\"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...</td>\n",
       "      <td>\"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...</td>\n",
       "      <td>\"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...</td>\n",
       "      <td>0.233803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d9a714b3484177f5fee5427d98c53a86bf48daf3</td>\n",
       "      <td>134</td>\n",
       "      <td>\"\"\"Tests for the sbahn_munich integration\"\"\"\\n...</td>\n",
       "      <td>\"\"\"Tests for the sbahn_munich integration\"\"\"\\n...</td>\n",
       "      <td>\"\"\"Tests for the sbahn_munich integration\"\"\"\\n...</td>\n",
       "      <td>0.096186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>8a6c4e202130d51c730ab01bd3f2f21e5ec32862</td>\n",
       "      <td>758</td>\n",
       "      <td>from tools.geofunc import GeoFunc\\nimport pand...</td>\n",
       "      <td>from tools.geofunc import GeoFunc\\nimport pand...</td>\n",
       "      <td>from tools.geofunc import GeoFunc\\nimport pand...</td>\n",
       "      <td>0.117258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>8a6c803544f7e0d285bc37ff4aefd197349a5940</td>\n",
       "      <td>456</td>\n",
       "      <td>#from trw.utils import collect_hierarchical_mo...</td>\n",
       "      <td>#from trw.utils import collect_hierarchical_mo...</td>\n",
       "      <td>#from trw.utils import collect_hierarchical_mo...</td>\n",
       "      <td>0.104595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>8a6dd286ad198b0a16465871a4cd84854d419ad0</td>\n",
       "      <td>1824</td>\n",
       "      <td>\"\"\"The module defines the abstract interface f...</td>\n",
       "      <td>\"\"\"The module defines the abstract interface f...</td>\n",
       "      <td>\"\"\"The module defines the abstract interface f...</td>\n",
       "      <td>0.361575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>8a6e9d6c995b4c34ef5a6722c4973c2c7fb333f1</td>\n",
       "      <td>1065</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\nimport glob\\nimport ...</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\nimport glob\\nimport ...</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\nimport glob\\nimport ...</td>\n",
       "      <td>0.128037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>8a6fea40902a5d1ec59a6cdd9117e96fcdef70a1</td>\n",
       "      <td>572</td>\n",
       "      <td># 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...</td>\n",
       "      <td># 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...</td>\n",
       "      <td># 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...</td>\n",
       "      <td>0.454399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       hexsha  size  \\\n",
       "0    d99a20277c32bb1e28312f42ab6d732f38323169   241   \n",
       "1    d99e8a9a95f28da6c2d4d1ee42e95a270ab08977   421   \n",
       "2    d99f875863138f11af1d76f0c753c198ad6d96bd  1329   \n",
       "3    d9a6621d903359b14c87695eb4a1ac8dcea18138   844   \n",
       "4    d9a714b3484177f5fee5427d98c53a86bf48daf3   134   \n",
       "..                                        ...   ...   \n",
       "123  8a6c4e202130d51c730ab01bd3f2f21e5ec32862   758   \n",
       "124  8a6c803544f7e0d285bc37ff4aefd197349a5940   456   \n",
       "125  8a6dd286ad198b0a16465871a4cd84854d419ad0  1824   \n",
       "126  8a6e9d6c995b4c34ef5a6722c4973c2c7fb333f1  1065   \n",
       "127  8a6fea40902a5d1ec59a6cdd9117e96fcdef70a1   572   \n",
       "\n",
       "                                               content  \\\n",
       "0    from django.contrib import admin\\nfrom .models...   \n",
       "1    class Solution:\\n    def finalPrices(self, pri...   \n",
       "2    # -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...   \n",
       "3    \"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...   \n",
       "4    \"\"\"Tests for the sbahn_munich integration\"\"\"\\n...   \n",
       "..                                                 ...   \n",
       "123  from tools.geofunc import GeoFunc\\nimport pand...   \n",
       "124  #from trw.utils import collect_hierarchical_mo...   \n",
       "125  \"\"\"The module defines the abstract interface f...   \n",
       "126  #!/usr/bin/env python3\\n\\nimport glob\\nimport ...   \n",
       "127  # 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...   \n",
       "\n",
       "                                         prediction_50  \\\n",
       "0    from django.contrib import admin\\nfrom.models ...   \n",
       "1    class Solution:\\n    def finalPrices(self, pri...   \n",
       "2    # -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...   \n",
       "3    \"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...   \n",
       "4    \"\"\"Tests for the sbahn_munich integration\"\"\"\\n...   \n",
       "..                                                 ...   \n",
       "123  from tools.geofunc import GeoFunc\\nimport pand...   \n",
       "124  #from trw.utils import collect_hierarchical_mo...   \n",
       "125  \"\"\"The module defines the abstract interface f...   \n",
       "126  #!/usr/bin/env python3\\n\\nimport glob\\nimport ...   \n",
       "127  # 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...   \n",
       "\n",
       "                                             prefix_50   bleu_50  \n",
       "0    from django.contrib import admin\\nfrom.models ...  1.000000  \n",
       "1    class Solution:\\n    def finalPrices(self, pri...  0.803812  \n",
       "2    # -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...  0.169206  \n",
       "3    \"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...  0.233803  \n",
       "4    \"\"\"Tests for the sbahn_munich integration\"\"\"\\n...  0.096186  \n",
       "..                                                 ...       ...  \n",
       "123  from tools.geofunc import GeoFunc\\nimport pand...  0.117258  \n",
       "124  #from trw.utils import collect_hierarchical_mo...  0.104595  \n",
       "125  \"\"\"The module defines the abstract interface f...  0.361575  \n",
       "126  #!/usr/bin/env python3\\n\\nimport glob\\nimport ...  0.128037  \n",
       "127  # 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...  0.454399  \n",
       "\n",
       "[128 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[begin:(end-1)] = block_df\n",
    "df.to_csv(\"samples.csv\", index=False)\n",
    "begin += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:(batch_size-1), \"prediction\"] = tokenizer.batch_decode(output, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prefix_50\"] = None\n",
    "df.loc[:(batch_size-1), \"prefix_50\"] = tokenizer.batch_decode(inputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 54, 'reference_length': 54}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "row = df.iloc[]\n",
    "predictions = row[\"prediction\"]\n",
    "references = row[\"content\"]\n",
    "\n",
    "results = bleu.compute(predictions=[predictions], references=[references])[\"bleu\"]\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hexsha</th>\n",
       "      <th>size</th>\n",
       "      <th>content</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prefix_50</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d99a20277c32bb1e28312f42ab6d732f38323169</td>\n",
       "      <td>241</td>\n",
       "      <td>from django.contrib import admin\\nfrom .models...</td>\n",
       "      <td>from django.contrib import admin\\nfrom.models ...</td>\n",
       "      <td>from django.contrib import admin\\nfrom.models ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d99e8a9a95f28da6c2d4d1ee42e95a270ab08977</td>\n",
       "      <td>421</td>\n",
       "      <td>class Solution:\\n    def finalPrices(self, pri...</td>\n",
       "      <td>class Solution:\\n    def finalPrices(self, pri...</td>\n",
       "      <td>class Solution:\\n    def finalPrices(self, pri...</td>\n",
       "      <td>0.803812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d99f875863138f11af1d76f0c753c198ad6d96bd</td>\n",
       "      <td>1329</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...</td>\n",
       "      <td>0.169206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d9a6621d903359b14c87695eb4a1ac8dcea18138</td>\n",
       "      <td>844</td>\n",
       "      <td>\"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...</td>\n",
       "      <td>\"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...</td>\n",
       "      <td>\"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...</td>\n",
       "      <td>0.233803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d9a714b3484177f5fee5427d98c53a86bf48daf3</td>\n",
       "      <td>134</td>\n",
       "      <td>\"\"\"Tests for the sbahn_munich integration\"\"\"\\n...</td>\n",
       "      <td>\"\"\"Tests for the sbahn_munich integration\"\"\"\\n...</td>\n",
       "      <td>\"\"\"Tests for the sbahn_munich integration\"\"\"\\n...</td>\n",
       "      <td>0.096186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>8a6c4e202130d51c730ab01bd3f2f21e5ec32862</td>\n",
       "      <td>758</td>\n",
       "      <td>from tools.geofunc import GeoFunc\\nimport pand...</td>\n",
       "      <td>from tools.geofunc import GeoFunc\\nimport pand...</td>\n",
       "      <td>from tools.geofunc import GeoFunc\\nimport pand...</td>\n",
       "      <td>0.117258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>8a6c803544f7e0d285bc37ff4aefd197349a5940</td>\n",
       "      <td>456</td>\n",
       "      <td>#from trw.utils import collect_hierarchical_mo...</td>\n",
       "      <td>#from trw.utils import collect_hierarchical_mo...</td>\n",
       "      <td>#from trw.utils import collect_hierarchical_mo...</td>\n",
       "      <td>0.104595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>8a6dd286ad198b0a16465871a4cd84854d419ad0</td>\n",
       "      <td>1824</td>\n",
       "      <td>\"\"\"The module defines the abstract interface f...</td>\n",
       "      <td>\"\"\"The module defines the abstract interface f...</td>\n",
       "      <td>\"\"\"The module defines the abstract interface f...</td>\n",
       "      <td>0.361575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>8a6e9d6c995b4c34ef5a6722c4973c2c7fb333f1</td>\n",
       "      <td>1065</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\nimport glob\\nimport ...</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\nimport glob\\nimport ...</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\nimport glob\\nimport ...</td>\n",
       "      <td>0.128037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>8a6fea40902a5d1ec59a6cdd9117e96fcdef70a1</td>\n",
       "      <td>572</td>\n",
       "      <td># 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...</td>\n",
       "      <td># 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...</td>\n",
       "      <td># 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...</td>\n",
       "      <td>0.454399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       hexsha  size  \\\n",
       "0    d99a20277c32bb1e28312f42ab6d732f38323169   241   \n",
       "1    d99e8a9a95f28da6c2d4d1ee42e95a270ab08977   421   \n",
       "2    d99f875863138f11af1d76f0c753c198ad6d96bd  1329   \n",
       "3    d9a6621d903359b14c87695eb4a1ac8dcea18138   844   \n",
       "4    d9a714b3484177f5fee5427d98c53a86bf48daf3   134   \n",
       "..                                        ...   ...   \n",
       "123  8a6c4e202130d51c730ab01bd3f2f21e5ec32862   758   \n",
       "124  8a6c803544f7e0d285bc37ff4aefd197349a5940   456   \n",
       "125  8a6dd286ad198b0a16465871a4cd84854d419ad0  1824   \n",
       "126  8a6e9d6c995b4c34ef5a6722c4973c2c7fb333f1  1065   \n",
       "127  8a6fea40902a5d1ec59a6cdd9117e96fcdef70a1   572   \n",
       "\n",
       "                                               content  \\\n",
       "0    from django.contrib import admin\\nfrom .models...   \n",
       "1    class Solution:\\n    def finalPrices(self, pri...   \n",
       "2    # -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...   \n",
       "3    \"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...   \n",
       "4    \"\"\"Tests for the sbahn_munich integration\"\"\"\\n...   \n",
       "..                                                 ...   \n",
       "123  from tools.geofunc import GeoFunc\\nimport pand...   \n",
       "124  #from trw.utils import collect_hierarchical_mo...   \n",
       "125  \"\"\"The module defines the abstract interface f...   \n",
       "126  #!/usr/bin/env python3\\n\\nimport glob\\nimport ...   \n",
       "127  # 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...   \n",
       "\n",
       "                                            prediction  \\\n",
       "0    from django.contrib import admin\\nfrom.models ...   \n",
       "1    class Solution:\\n    def finalPrices(self, pri...   \n",
       "2    # -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...   \n",
       "3    \"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...   \n",
       "4    \"\"\"Tests for the sbahn_munich integration\"\"\"\\n...   \n",
       "..                                                 ...   \n",
       "123  from tools.geofunc import GeoFunc\\nimport pand...   \n",
       "124  #from trw.utils import collect_hierarchical_mo...   \n",
       "125  \"\"\"The module defines the abstract interface f...   \n",
       "126  #!/usr/bin/env python3\\n\\nimport glob\\nimport ...   \n",
       "127  # 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...   \n",
       "\n",
       "                                             prefix_50      bleu  \n",
       "0    from django.contrib import admin\\nfrom.models ...  1.000000  \n",
       "1    class Solution:\\n    def finalPrices(self, pri...  0.803812  \n",
       "2    # -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...  0.169206  \n",
       "3    \"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...  0.233803  \n",
       "4    \"\"\"Tests for the sbahn_munich integration\"\"\"\\n...  0.096186  \n",
       "..                                                 ...       ...  \n",
       "123  from tools.geofunc import GeoFunc\\nimport pand...  0.117258  \n",
       "124  #from trw.utils import collect_hierarchical_mo...  0.104595  \n",
       "125  \"\"\"The module defines the abstract interface f...  0.361575  \n",
       "126  #!/usr/bin/env python3\\n\\nimport glob\\nimport ...  0.128037  \n",
       "127  # 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...  0.454399  \n",
       "\n",
       "[128 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_df = df.iloc[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hexsha</th>\n",
       "      <th>size</th>\n",
       "      <th>content</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prefix_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d99a20277c32bb1e28312f42ab6d732f38323169</td>\n",
       "      <td>241</td>\n",
       "      <td>from django.contrib import admin\\nfrom .models...</td>\n",
       "      <td>from django.contrib import admin\\nfrom.models ...</td>\n",
       "      <td>from django.contrib import admin\\nfrom.models ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d99e8a9a95f28da6c2d4d1ee42e95a270ab08977</td>\n",
       "      <td>421</td>\n",
       "      <td>class Solution:\\n    def finalPrices(self, pri...</td>\n",
       "      <td>class Solution:\\n    def finalPrices(self, pri...</td>\n",
       "      <td>class Solution:\\n    def finalPrices(self, pri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d99f875863138f11af1d76f0c753c198ad6d96bd</td>\n",
       "      <td>1329</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d9a6621d903359b14c87695eb4a1ac8dcea18138</td>\n",
       "      <td>844</td>\n",
       "      <td>\"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...</td>\n",
       "      <td>\"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...</td>\n",
       "      <td>\"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d9a714b3484177f5fee5427d98c53a86bf48daf3</td>\n",
       "      <td>134</td>\n",
       "      <td>\"\"\"Tests for the sbahn_munich integration\"\"\"\\n...</td>\n",
       "      <td>\"\"\"Tests for the sbahn_munich integration\"\"\"\\n...</td>\n",
       "      <td>\"\"\"Tests for the sbahn_munich integration\"\"\"\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>8a6c4e202130d51c730ab01bd3f2f21e5ec32862</td>\n",
       "      <td>758</td>\n",
       "      <td>from tools.geofunc import GeoFunc\\nimport pand...</td>\n",
       "      <td>from tools.geofunc import GeoFunc\\nimport pand...</td>\n",
       "      <td>from tools.geofunc import GeoFunc\\nimport pand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>8a6c803544f7e0d285bc37ff4aefd197349a5940</td>\n",
       "      <td>456</td>\n",
       "      <td>#from trw.utils import collect_hierarchical_mo...</td>\n",
       "      <td>#from trw.utils import collect_hierarchical_mo...</td>\n",
       "      <td>#from trw.utils import collect_hierarchical_mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>8a6dd286ad198b0a16465871a4cd84854d419ad0</td>\n",
       "      <td>1824</td>\n",
       "      <td>\"\"\"The module defines the abstract interface f...</td>\n",
       "      <td>\"\"\"The module defines the abstract interface f...</td>\n",
       "      <td>\"\"\"The module defines the abstract interface f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>8a6e9d6c995b4c34ef5a6722c4973c2c7fb333f1</td>\n",
       "      <td>1065</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\nimport glob\\nimport ...</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\nimport glob\\nimport ...</td>\n",
       "      <td>#!/usr/bin/env python3\\n\\nimport glob\\nimport ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>8a6fea40902a5d1ec59a6cdd9117e96fcdef70a1</td>\n",
       "      <td>572</td>\n",
       "      <td># 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...</td>\n",
       "      <td># 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...</td>\n",
       "      <td># 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       hexsha  size  \\\n",
       "0    d99a20277c32bb1e28312f42ab6d732f38323169   241   \n",
       "1    d99e8a9a95f28da6c2d4d1ee42e95a270ab08977   421   \n",
       "2    d99f875863138f11af1d76f0c753c198ad6d96bd  1329   \n",
       "3    d9a6621d903359b14c87695eb4a1ac8dcea18138   844   \n",
       "4    d9a714b3484177f5fee5427d98c53a86bf48daf3   134   \n",
       "..                                        ...   ...   \n",
       "123  8a6c4e202130d51c730ab01bd3f2f21e5ec32862   758   \n",
       "124  8a6c803544f7e0d285bc37ff4aefd197349a5940   456   \n",
       "125  8a6dd286ad198b0a16465871a4cd84854d419ad0  1824   \n",
       "126  8a6e9d6c995b4c34ef5a6722c4973c2c7fb333f1  1065   \n",
       "127  8a6fea40902a5d1ec59a6cdd9117e96fcdef70a1   572   \n",
       "\n",
       "                                               content  \\\n",
       "0    from django.contrib import admin\\nfrom .models...   \n",
       "1    class Solution:\\n    def finalPrices(self, pri...   \n",
       "2    # -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...   \n",
       "3    \"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...   \n",
       "4    \"\"\"Tests for the sbahn_munich integration\"\"\"\\n...   \n",
       "..                                                 ...   \n",
       "123  from tools.geofunc import GeoFunc\\nimport pand...   \n",
       "124  #from trw.utils import collect_hierarchical_mo...   \n",
       "125  \"\"\"The module defines the abstract interface f...   \n",
       "126  #!/usr/bin/env python3\\n\\nimport glob\\nimport ...   \n",
       "127  # 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...   \n",
       "\n",
       "                                            prediction  \\\n",
       "0    from django.contrib import admin\\nfrom.models ...   \n",
       "1    class Solution:\\n    def finalPrices(self, pri...   \n",
       "2    # -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...   \n",
       "3    \"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...   \n",
       "4    \"\"\"Tests for the sbahn_munich integration\"\"\"\\n...   \n",
       "..                                                 ...   \n",
       "123  from tools.geofunc import GeoFunc\\nimport pand...   \n",
       "124  #from trw.utils import collect_hierarchical_mo...   \n",
       "125  \"\"\"The module defines the abstract interface f...   \n",
       "126  #!/usr/bin/env python3\\n\\nimport glob\\nimport ...   \n",
       "127  # 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...   \n",
       "\n",
       "                                             prefix_50  \n",
       "0    from django.contrib import admin\\nfrom.models ...  \n",
       "1    class Solution:\\n    def finalPrices(self, pri...  \n",
       "2    # -*- coding: utf-8 -*-\\n\\n\"\"\"Context managers...  \n",
       "3    \"\"\"Utils for criterion.\"\"\"\\nimport torch\\nimpo...  \n",
       "4    \"\"\"Tests for the sbahn_munich integration\"\"\"\\n...  \n",
       "..                                                 ...  \n",
       "123  from tools.geofunc import GeoFunc\\nimport pand...  \n",
       "124  #from trw.utils import collect_hierarchical_mo...  \n",
       "125  \"\"\"The module defines the abstract interface f...  \n",
       "126  #!/usr/bin/env python3\\n\\nimport glob\\nimport ...  \n",
       "127  # 题意：给出一个仅包含字符'(',')','{','}','['和']',的字符串，判断给...  \n",
       "\n",
       "[128 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "block_df[\"bleu\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/code_memorization_starcoder/experiment.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m block_df[:,\u001b[39m\"\u001b[39;49m\u001b[39mbleu\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m block_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                                   bleu\u001b[39m.\u001b[39mcompute(predictions\u001b[39m=\u001b[39m[row[\u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m]],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                                                 references\u001b[39m=\u001b[39m[row[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]])[\u001b[39m\"\u001b[39m\u001b[39mbleu\u001b[39m\u001b[39m\"\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/pandas/core/frame.py:4094\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4091\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4092\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4093\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 4094\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/pandas/core/frame.py:4306\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4294\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4295\u001b[0m \u001b[39mAdd series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4296\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4301\u001b[0m \u001b[39mensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4302\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4303\u001b[0m value, refs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m   4305\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m-> 4306\u001b[0m     key \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\n\u001b[1;32m   4307\u001b[0m     \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4308\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4309\u001b[0m ):\n\u001b[1;32m   4310\u001b[0m     \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4311\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n\u001b[1;32m   4312\u001b[0m         existing_piece \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m[key]\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/pandas/core/indexes/base.py:5334\u001b[0m, in \u001b[0;36mIndex.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__contains__\u001b[39m(\u001b[39mself\u001b[39m, key: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   5300\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5301\u001b[0m \u001b[39m    Return a boolean indicating whether the provided key is in the index.\u001b[39;00m\n\u001b[1;32m   5302\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5332\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m   5333\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5334\u001b[0m     \u001b[39mhash\u001b[39;49m(key)\n\u001b[1;32m   5335\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   5336\u001b[0m         \u001b[39mreturn\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "block_df[:,\"bleu\"] = block_df.apply(lambda row: \n",
    "                                  bleu.compute(predictions=[row[\"prediction\"]],\n",
    "                                                references=[row[\"content\"]])[\"bleu\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.00\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "reference = [\"The\", \"cat\", \"is\", \"on\", \"the\", \"mat\"]\n",
    "candidate = [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
    "\n",
    "bleu_score = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "print(f'BLEU score: {bleu_score*100:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bleu\"] = None\n",
    "df.loc[:(batch_size-1), \"bleu\"] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Mon Oct  9 00:40:59 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  Off  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    59W / 300W |  75544MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1129      G   /usr/lib/xorg/Xorg                130MiB |\n",
      "|    0   N/A  N/A      1471      G   /usr/bin/gnome-shell               12MiB |\n",
      "|    0   N/A  N/A      5652      C   ...nda3/envs/eval/bin/python    75396MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"samples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "from django.contrib import admin\n",
      "from .models import SearchResult\n",
      "\n",
      "# Register your models here.\n",
      "class SearchResultAdmin(admin.ModelAdmin):\n",
      "    fields = [\"query\", \"heading\", \"url\", \"text\"]\n",
      "\n",
      "admin.site.register(SearchResult, SearchResultAdmin)\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "from django.contrib import admin\n",
      "from.models import SearchResult\n",
      "\n",
      "# Register your models here.\n",
      "class SearchResultAdmin(admin.ModelAdmin):\n",
      "    fields = [\"query\", \"heading\", \"url\", \"text\"]\n",
      "\n",
      "admin\n",
      "------------------------------\n",
      "Original:\n",
      "class Solution:\n",
      "    def finalPrices(self, prices: List[int]) -> List[int]:\n",
      "        res = []\n",
      "        for i in range(len(prices)):\n",
      "            for j in range(i+1,len(prices)):\n",
      "                if prices[j]<=prices[i]:\n",
      "                    res.append(prices[i]-prices[j])\n",
      "                    break\n",
      "                if j==len(prices)-1:\n",
      "                    res.append(prices[i])\n",
      "        res.append(prices[-1])\n",
      "        return res\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "class Solution:\n",
      "    def finalPrices(self, prices: List[int]) -> List[int]:\n",
      "        res = []\n",
      "        for i in range(len(prices)):\n",
      "            for j in range(i+1,len(prices)):\n",
      "               \n",
      "------------------------------\n",
      "Original:\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "\"\"\"Context managers implemented for (mostly) internal use\"\"\"\n",
      "\n",
      "import contextlib\n",
      "import functools\n",
      "from io import UnsupportedOperation\n",
      "import os\n",
      "import sys\n",
      "\n",
      "\n",
      "__all__ = [\"RedirectStdout\", \"RedirectStderr\"]\n",
      "\n",
      "\n",
      "@contextlib.contextmanager\n",
      "def _stdchannel_redirected(stdchannel, dest_filename, mode=\"w\"):\n",
      "    \"\"\"\n",
      "    A context manager to temporarily redirect stdout or stderr\n",
      "\n",
      "    Originally by Marc Abramowitz, 2013\n",
      "    (http://marc-abramowitz.com/archives/2013/07/19/python-context-manager-for-redirected-stdout-and-stderr/)\n",
      "    \"\"\"\n",
      "\n",
      "    oldstdchannel = None\n",
      "    dest_file = None\n",
      "    try:\n",
      "        if stdchannel is None:\n",
      "            yield iter([None])\n",
      "        else:\n",
      "            oldstdchannel = os.dup(stdchannel.fileno())\n",
      "            dest_file = open(dest_filename, mode)\n",
      "            os.dup2(dest_file.fileno(), stdchannel.fileno())\n",
      "            yield\n",
      "    except (UnsupportedOperation, AttributeError):\n",
      "        yield iter([None])\n",
      "    finally:\n",
      "        if oldstdchannel is not None:\n",
      "            os.dup2(oldstdchannel, stdchannel.fileno())\n",
      "        if dest_file is not None:\n",
      "            dest_file.close()\n",
      "\n",
      "\n",
      "RedirectStdout = functools.partial(_stdchannel_redirected, sys.stdout)\n",
      "RedirectStderr = functools.partial(_stdchannel_redirected, sys.stderr)\n",
      "RedirectNoOp = functools.partial(_stdchannel_redirected, None, \"\")\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "# -*- coding: utf-8 -*-\n",
      "\n",
      "\"\"\"Context managers implemented for (mostly) internal use\"\"\"\n",
      "\n",
      "import contextlib\n",
      "import functools\n",
      "from io import UnsupportedOperation\n",
      "import os\n",
      "import sys\n",
      "\n",
      "\n",
      "__all__ = [\"Redirect\n",
      "------------------------------\n",
      "Original:\n",
      "\"\"\"Utils for criterion.\"\"\"\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "\n",
      "\n",
      "def normalize(x, axis=-1):\n",
      "    \"\"\"Performs L2-Norm.\"\"\"\n",
      "    num = x\n",
      "    denom = torch.norm(x, 2, axis, keepdim=True).expand_as(x) + 1e-12\n",
      "    return num / denom\n",
      "\n",
      "\n",
      "# Source : https://github.com/earhian/Humpback-Whale-Identification-1st-/blob/master/models/triplet_loss.py\n",
      "def euclidean_dist(x, y):\n",
      "    \"\"\"Computes Euclidean distance.\"\"\"\n",
      "    m, n = x.size(0), y.size(0)\n",
      "    xx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\n",
      "    yy = torch.pow(x, 2).sum(1, keepdim=True).expand(m, m).t()\n",
      "    dist = xx + yy - 2 * torch.matmul(x, y.t())\n",
      "\n",
      "    dist = dist.clamp(min=1e-12).sqrt()\n",
      "\n",
      "    return dist\n",
      "\n",
      "\n",
      "def cosine_dist(x, y):\n",
      "    \"\"\"Computes Cosine Distance.\"\"\"\n",
      "    x = F.normalize(x, dim=1)\n",
      "    y = F.normalize(y, dim=1)\n",
      "    dist = 2 - 2 * torch.mm(x, y.t())\n",
      "    return dist\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "\"\"\"Utils for criterion.\"\"\"\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "\n",
      "\n",
      "def normalize(x, axis=-1):\n",
      "    \"\"\"Performs L2-Norm.\"\"\"\n",
      "    num = x\n",
      "    denom = torch.norm(x,\n",
      "------------------------------\n",
      "Original:\n",
      "\"\"\"Tests for the sbahn_munich integration\"\"\"\n",
      "\n",
      "\n",
      "line_dict = {\n",
      "    \"name\": \"S3\",\n",
      "    \"color\": \"#333333\",\n",
      "    \"text_color\": \"#444444\",\n",
      "}\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "\"\"\"Tests for the sbahn_munich integration\"\"\"\n",
      "\n",
      "\n",
      "line_dict = {\n",
      "    \"name\": \"S3\",\n",
      "    \"color\": \"#333333\",\n",
      "    \"text_color\": \"#4444\n",
      "------------------------------\n",
      "Original:\n",
      "#! /usr/bin/env python2.7\n",
      "# -*- coding: latin-1 -*-\n",
      "\n",
      "from flask import Blueprint\n",
      "from flask import current_app\n",
      "from flask import render_template\n",
      "\n",
      "from flask_login import login_required\n",
      "\n",
      "homestack = Blueprint(\"homestack\", __name__, url_prefix=\"/homestack\")\n",
      "\n",
      "\n",
      "@homestack.route(\"/\", methods=[\"GET\"])\n",
      "@login_required\n",
      "def home():\n",
      "    return render_template(\"homestack/home.html\")\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "#! /usr/bin/env python2.7\n",
      "# -*- coding: latin-1 -*-\n",
      "\n",
      "from flask import Blueprint\n",
      "from flask import current_app\n",
      "from flask import render_template\n",
      "\n",
      "from flask_login import login_required\n",
      "------------------------------\n",
      "Original:\n",
      "import setuptools  #enables develop\n",
      "\n",
      "setuptools.setup(\n",
      "    name='pysvm',\n",
      "    version='0.1',\n",
      "    description='PySVM : A NumPy implementation of SVM based on SMO algorithm',\n",
      "    author_email=\"191300064@smail.nju.edu.cn\",\n",
      "    packages=['pysvm'],\n",
      "    license='MIT License',\n",
      "    long_description=open('README.md', encoding='utf-8').read(),\n",
      "    install_requires=[  #自动安装依赖\n",
      "        'numpy', 'sklearn'\n",
      "    ],\n",
      "    url='https://github.com/Kaslanarian/PySVM',\n",
      ")\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "import setuptools  #enables develop\n",
      "\n",
      "setuptools.setup(\n",
      "    name='pysvm',\n",
      "    version='0.1',\n",
      "    description='PySVM : A NumPy implementation of SVM based on SMO algorithm',\n",
      "    author_email\n",
      "------------------------------\n",
      "Original:\n",
      "from data_collection.management.commands import BaseXpressDemocracyClubCsvImporter\n",
      "\n",
      "class Command(BaseXpressDemocracyClubCsvImporter):\n",
      "    council_id = 'E06000027'\n",
      "    addresses_name = 'parl.2017-06-08/Version 1/Torbay Democracy_Club__08June2017.tsv'\n",
      "    stations_name = 'parl.2017-06-08/Version 1/Torbay Democracy_Club__08June2017.tsv'\n",
      "    elections = ['parl.2017-06-08']\n",
      "    csv_delimiter = '\\t'\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "from data_collection.management.commands import BaseXpressDemocracyClubCsvImporter\n",
      "\n",
      "class Command(BaseXpressDemocracyClubCsvImporter):\n",
      "    council_id = 'E06000027'\n",
      "    addresses\n",
      "------------------------------\n",
      "Original:\n",
      "from django.db.models import Q\n",
      "\n",
      "from django.shortcuts import render\n",
      "from django.http import Http404\n",
      "\n",
      "# Create your views here.\n",
      "from rest_framework.views import APIView\n",
      "from rest_framework.response import Response\n",
      "from rest_framework.decorators import api_view\n",
      "\n",
      "from .models import Product, Category\n",
      "from .serializers import ProductSerializer, CategorySerializer\n",
      "\n",
      "class LatestProductsList(APIView):\n",
      "    def get(self, request, format=None):\n",
      "        products = Product.objects.all()[0:4]\n",
      "        serializer = ProductSerializer(products,many=True)\n",
      "        return Response(serializer.data)\n",
      "\n",
      "class ProductDetail(APIView):\n",
      "    def get_object(self, category_slug, product_slug):\n",
      "        try:\n",
      "            return Product.objects.filter(category__slug=category_slug).get(slug=product_slug)\n",
      "        except Product.DoesNotExist:\n",
      "            raise Http404\n",
      "\n",
      "    def get(self, request, category_slug, product_slug, format= None):\n",
      "        product = self.get_object(category_slug, product_slug)\n",
      "        serializer = ProductSerializer(product)\n",
      "        return Response(serializer.data)\n",
      "\n",
      "class CategoryDetail(APIView):\n",
      "    def get_object(self, category_slug):\n",
      "        try:\n",
      "            return Category.objects.get(slug=category_slug)\n",
      "        except Category.DoesNotExist:\n",
      "            raise Http404\n",
      "    \n",
      "    def get(self, request, category_slug, format= None):\n",
      "        category = self.get_object(category_slug)\n",
      "        serializer = CategorySerializer(category)\n",
      "        return Response(serializer.data)\n",
      "\n",
      "@api_view(['POST'])\n",
      "def search(request):\n",
      "    query = request.data.get('query', '')\n",
      "\n",
      "    if query:\n",
      "        products = Product.objects.filter(Q(name__icontains=query) | Q(description__icontains=query))\n",
      "        serializer = ProductSerializer(products, many=True)\n",
      "        return Response(serializer.data)\n",
      "    else:\n",
      "        return Response({\"products\": []})\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "from django.db.models import Q\n",
      "\n",
      "from django.shortcuts import render\n",
      "from django.http import Http404\n",
      "\n",
      "# Create your views here.\n",
      "from rest_framework.views import APIView\n",
      "from rest_framework.\n",
      "------------------------------\n",
      "Original:\n",
      "from sys import maxsize\n",
      "\n",
      "\n",
      "class Contact:\n",
      "\n",
      "    def __init__(self, fname=None, mname=None, lname=None, nick=None, title=None, comp=None, addr=None,\n",
      "                 home=None, mobile=None, work=None, fax=None, email1=None, email2=None, email3=None,\n",
      "                 homepage=None, bday=None, bmonth=None, byear=None, aday=None, amonth=None, ayear=None,\n",
      "                 secaddr=None, secphone=None, note=None, id =None):\n",
      "        self.fname = fname\n",
      "        self.mname = mname\n",
      "        self.lname = lname\n",
      "        self.nick = nick\n",
      "        self.title = title\n",
      "        self.comp = comp\n",
      "        self.addr = addr\n",
      "        self.home = home\n",
      "        self.mobile = mobile\n",
      "        self.work = work\n",
      "        self.fax = fax\n",
      "        self.email1 = email1\n",
      "        self.email2 = email2\n",
      "        self.email3 = email3\n",
      "        self.homepage = homepage\n",
      "        self.bday = bday\n",
      "        self.bmonth = bmonth\n",
      "        self.byear = byear\n",
      "        self.aday = aday\n",
      "        self.amonth = amonth\n",
      "        self.ayear = ayear\n",
      "        self.secaddr = secaddr\n",
      "        self.secphone = secphone\n",
      "        self.note = note\n",
      "        self.id = id\n",
      "\n",
      "    def __repr__(self):\n",
      "        return \"%s:%s:%s\" % (self.id, self.fname, self.lname)\n",
      "\n",
      "    def __eq__(self, other):\n",
      "        return (self.id is None or other.id is None or self.id == other.id) and self.fname == other.fname and self.lname == other.lname\n",
      "\n",
      "    def id_or_max(self):\n",
      "        if self.id:\n",
      "            return int(self.id)\n",
      "        else:\n",
      "            return maxsize\n",
      "\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "from sys import maxsize\n",
      "\n",
      "\n",
      "class Contact:\n",
      "\n",
      "    def __init__(self, fname=None, mname=None, lname=None, nick=None, title=None, comp=None, addr=None,\n",
      "                 home=\n",
      "------------------------------\n",
      "Original:\n",
      "from zeit.cms.i18n import MessageFactory as _\n",
      "import zope.interface\n",
      "import zope.schema\n",
      "\n",
      "\n",
      "class IGlobalSettings(zope.interface.Interface):\n",
      "    \"\"\"Global CMS settings.\"\"\"\n",
      "\n",
      "    default_year = zope.schema.Int(\n",
      "        title=_(\"Default year\"),\n",
      "        min=1900,\n",
      "        max=2100)\n",
      "\n",
      "    default_volume = zope.schema.Int(\n",
      "        title=_(\"Default volume\"),\n",
      "        min=1,\n",
      "        max=54)\n",
      "\n",
      "    def get_working_directory(template):\n",
      "        \"\"\"Return the collection which is the main working directory.\n",
      "\n",
      "        template:\n",
      "            Template which will be filled with year and volume. In\n",
      "            ``template`` the placeholders $year and $volume will be replaced.\n",
      "            Example: 'online/$year/$volume/foo'\n",
      "\n",
      "        If the respective collection does not exist, it will be created before\n",
      "        returning it.\n",
      "\n",
      "        \"\"\"\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "from zeit.cms.i18n import MessageFactory as _\n",
      "import zope.interface\n",
      "import zope.schema\n",
      "\n",
      "\n",
      "class IGlobalSettings(zope.interface.Interface):\n",
      "    \"\"\"Global CMS settings.\"\"\"\n",
      "\n",
      "    default_\n",
      "------------------------------\n",
      "Original:\n",
      "N, M = map(int, input().split())\n",
      "\n",
      "for i in range(1, M + 1):\n",
      "    if i % 2 == 1:\n",
      "        j = (i - 1) // 2\n",
      "        print(1 + j, M + 1 - j)\n",
      "    else:\n",
      "        j = (i - 2) // 2\n",
      "        print(M + 2 + j, 2 * M + 1 - j)\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "N, M = map(int, input().split())\n",
      "\n",
      "for i in range(1, M + 1):\n",
      "    if i % 2 == 1:\n",
      "        j = (i - 1) // 2\n",
      "        print\n",
      "------------------------------\n",
      "Original:\n",
      "# for n in range(400,500):\n",
      "#     i = n // 100\n",
      "#     j = n // 10 % 10\n",
      "#     k = n % 10\n",
      "#     if n == i ** 3 + j ** 3 + k ** 3:\n",
      "#         print(n)\n",
      "\n",
      "\n",
      "# 第一道题(16)\n",
      "# input(\"请输入(第一次):\")\n",
      "# s1 = input(\"请输入(第二次):\")\n",
      "\n",
      "# l1 = s1.split(' ')\n",
      "# l2 = []\n",
      "# for i in l1:\n",
      "#     if i.isdigit():\n",
      "#         l2.append(int(i))\n",
      "\n",
      "# for i in l2:\n",
      "#     if not (i % 6):\n",
      "#         print(i, end=\" \")\n",
      "\n",
      "# 第二道题(17)\n",
      "out_l1 = []\n",
      "def bian_int_list(l1):\n",
      "    re_l1 = []  # 返回出去的列表\n",
      "    for i in l1:\n",
      "        re_l1.append(i)\n",
      "\n",
      "def jisuan(str_num):\n",
      "    he1 = 0\n",
      "    global out_l1\n",
      "\n",
      "    for i in l1():\n",
      "        he1 += int(i)**2\n",
      "\n",
      "    if he1 > int(str_num):\n",
      "        out_l1.append(str_num)\n",
      "    return None\n",
      "\n",
      "while 1:\n",
      "    in_1 = input(\"请输入数值:\")\n",
      "    nums_l1 = in_1.split(' ')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "# for n in range(400,500):\n",
      "#     i = n // 100\n",
      "#     j = n // 10 % 10\n",
      "#     k = n % 10\n",
      "\n",
      "------------------------------\n",
      "Original:\n",
      "#!/usr/bin/python3.6.8+\n",
      "# -*- coding:utf-8 -*-\n",
      "\"\"\"\n",
      "@auth: cml\n",
      "@date: 2020-12-2\n",
      "@desc: ...\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class JobStatus(object):\n",
      "    PENDING = 0  # 任务等待执行\n",
      "\n",
      "    STARTED = 100  # 任务执行开始\n",
      "    PROCESS = 110\n",
      "    POLLING = 120\n",
      "    CALLBACK = 130\n",
      "\n",
      "    SUCCESS = 200   # 任务执行成功\n",
      "    RETRY = 300     # 任务重试\n",
      "    FAILURE = 400   # 任务执行失败\n",
      "    REVOKED = 500   # 任务撤销\n",
      "\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "#!/usr/bin/python3.6.8+\n",
      "# -*- coding:utf-8 -*-\n",
      "\"\"\"\n",
      "@auth: cml\n",
      "@date: 2020-12-2\n",
      "@desc:...\n",
      "\"\"\"\n",
      "------------------------------\n",
      "Original:\n",
      "import imtreat\n",
      "\n",
      "img = imtreat.imageManagerClass.openImageFunction(\"../images/soleil.png\", 0)\n",
      "\n",
      "img = imtreat.definedModesClass.detailEnhanceFunction(img)\n",
      "\n",
      "imtreat.imageManagerClass.saveImageFunction(\"/Téléchargements/\", \"image_1\", \".png\", img)\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "import imtreat\n",
      "\n",
      "img = imtreat.imageManagerClass.openImageFunction(\"../images/soleil.png\", 0)\n",
      "\n",
      "img = imtreat.definedModesClass.detailEnhanceFunction(img)\n",
      "\n",
      "------------------------------\n",
      "Original:\n",
      "import requests\n",
      "\n",
      "words_list = requests.get(\"https://raw.githubusercontent.com/atebits/Words/master/Words/fr.txt\").text\n",
      "\n",
      "words_list = filter(lambda x: len(x) > 4, words_list.split('\\n'))\n",
      "\n",
      "path = input(\"Chemin d'écriture ? (words.txt) \")\n",
      "\n",
      "if path == \"\":\n",
      "    path = \"./words.txt\"\n",
      "\n",
      "with open(path, \"w\", encoding=\"utf-8\") as file:\n",
      "    file.write('\\n'.join(words_list))\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "import requests\n",
      "\n",
      "words_list = requests.get(\"https://raw.githubusercontent.com/atebits/Words/master/Words/fr.txt\").text\n",
      "\n",
      "words_list = filter(lambda x: len(x) >\n",
      "------------------------------\n",
      "Original:\n",
      "import unittest\n",
      "from unittest import mock\n",
      "import os\n",
      "import subprocess\n",
      "from testfixtures import TempDirectory\n",
      "from simplegallery.upload.uploader_factory import get_uploader\n",
      "\n",
      "\n",
      "class AWSUploaderTestCase(unittest.TestCase):\n",
      "\n",
      "    def test_no_location(self):\n",
      "        uploader = get_uploader('aws')\n",
      "        self.assertFalse(uploader.check_location(''))\n",
      "\n",
      "    @mock.patch('subprocess.run')\n",
      "    def test_upload_gallery(self, subprocess_run):\n",
      "        subprocess_run.return_value = subprocess.CompletedProcess([], returncode=0)\n",
      "\n",
      "        with TempDirectory() as tempdir:\n",
      "            # Setup mock file and uploader\n",
      "            tempdir.write('index.html', b'')\n",
      "            gallery_path = os.path.join(tempdir.path, 'index.html')\n",
      "            uploader = get_uploader('aws')\n",
      "\n",
      "            # Test upload to bucket\n",
      "            uploader.upload_gallery('s3://testbucket/path/', gallery_path)\n",
      "            subprocess_run.assert_called_with(\n",
      "                ['aws', 's3', 'sync', gallery_path, 's3://testbucket/path/', '--exclude', '.DS_Store'])\n",
      "\n",
      "            # Test upload to bucket without prefix\n",
      "            uploader.upload_gallery('testbucket/path/', gallery_path)\n",
      "            subprocess_run.assert_called_with(\n",
      "                ['aws', 's3', 'sync', gallery_path, 's3://testbucket/path/', '--exclude', '.DS_Store'])\n",
      "\n",
      "            # Test upload to bucket without trailing /\n",
      "            uploader.upload_gallery('s3://testbucket/path', gallery_path)\n",
      "            subprocess_run.assert_called_with(\n",
      "                ['aws', 's3', 'sync', gallery_path, 's3://testbucket/path/', '--exclude', '.DS_Store'])\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "import unittest\n",
      "from unittest import mock\n",
      "import os\n",
      "import subprocess\n",
      "from testfixtures import TempDirectory\n",
      "from simplegallery.upload.uploader_factory import get_uploader\n",
      "\n",
      "\n",
      "class AWSUploaderTestCase(unittest.TestCase):\n",
      "\n",
      "    def test_no\n",
      "------------------------------\n",
      "Original:\n",
      "#!/usr/bin/env python\n",
      "import time\n",
      "import os\n",
      "import math\n",
      "from trackball import TrackBall\n",
      "\n",
      "print(\"\"\"Trackball: Mouse\n",
      "\n",
      "Use the trackball as a mouse in Raspbian, with right-click\n",
      "when the switch is pressed.\n",
      "\n",
      "Press Ctrl+C to exit!\n",
      "\"\"\")\n",
      "\n",
      "trackball = TrackBall(interrupt_pin=4)\n",
      "trackball.set_rgbw(0, 0, 0, 0)\n",
      "\n",
      "# Check for xte (used to control mouse)\n",
      "use_xte = os.system('which xte') == 0\n",
      "\n",
      "if use_xte == 0:\n",
      "    raise RuntimeError(\"xte not found. Did you sudo apt install xautomation?\")\n",
      "\n",
      "while True:\n",
      "    up, down, left, right, switch, state = trackball.read()\n",
      "\n",
      "    # Send movements and clicks to xte\n",
      "    if switch:\n",
      "        cmd = 'xte \"mouseclick 1\"'\n",
      "        os.system(cmd)\n",
      "    elif right or up or left or down:\n",
      "        x = right - left\n",
      "        x = math.copysign(x**2, x)\n",
      "        y = down - up\n",
      "        y = math.copysign(y**2, y)\n",
      "        cmd = 'xte \"mousermove {} {}\"'.format(int(x), int(y))\n",
      "        os.system(cmd)\n",
      "\n",
      "    time.sleep(0.0001)\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "#!/usr/bin/env python\n",
      "import time\n",
      "import os\n",
      "import math\n",
      "from trackball import TrackBall\n",
      "\n",
      "print(\"\"\"Trackball: Mouse\n",
      "\n",
      "Use the trackball as a mouse in Raspbian, with right-click\n",
      "------------------------------\n",
      "Original:\n",
      "\"\"\"Model Parameters Module.\"\"\"\n",
      "import torch.optim as optim\n",
      "from .search import SamplingSearch, GreedySearch, BeamSearch\n",
      "\n",
      "SEARCH_FACTORY = {\n",
      "    'sampling': SamplingSearch,\n",
      "    'greedy': GreedySearch,\n",
      "    'beam': BeamSearch,\n",
      "}\n",
      "\n",
      "OPTIMIZER_FACTORY = {\n",
      "    'adadelta': optim.Adadelta,\n",
      "    'adagrad': optim.Adagrad,\n",
      "    'adam': optim.Adam,\n",
      "    'adamax': optim.Adamax,\n",
      "    'rmsprop': optim.RMSprop,\n",
      "    'sgd': optim.SGD\n",
      "}\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "\"\"\"Model Parameters Module.\"\"\"\n",
      "import torch.optim as optim\n",
      "from.search import SamplingSearch, GreedySearch, BeamSearch\n",
      "\n",
      "SEARCH_FACTORY = {\n",
      "   'sampling': SamplingSearch,\n",
      "    'greedy': Greedy\n",
      "------------------------------\n",
      "Original:\n",
      "from floodsystem.stationdata import build_station_list\n",
      "from floodsystem.flood import stations_highest_rel_level\n",
      "\n",
      "def run():\n",
      "    stations = build_station_list()\n",
      "    warning_stations = stations_highest_rel_level(stations,10)\n",
      "    for entry in warning_stations:\n",
      "        print(entry[0].name,entry[1])\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    print(\"*** Task 2C: CUED Part IA Flood Warning System ***\")\n",
      "    run()\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "from floodsystem.stationdata import build_station_list\n",
      "from floodsystem.flood import stations_highest_rel_level\n",
      "\n",
      "def run():\n",
      "    stations = build_station_list()\n",
      "    warning_stations = stations_\n",
      "------------------------------\n",
      "Original:\n",
      "# This source code is part of the Biotite package and is distributed\n",
      "# under the 3-Clause BSD License. Please see 'LICENSE.rst' for further\n",
      "# information.\n",
      "\n",
      "__name__ = \"biotite\"\n",
      "__author__ = \"Patrick Kunzmann\"\n",
      "__all__ = [\"Copyable\"]\n",
      "\n",
      "import abc\n",
      "\n",
      "\n",
      "class Copyable(metaclass=abc.ABCMeta):\n",
      "    \"\"\"\n",
      "    Base class for all objects, that should be copyable.\n",
      "    \n",
      "    The public method `copy()` first creates a fresh instance of the\n",
      "    class of the instance, that is copied via the `__copy_create__()`\n",
      "    method. All variables, that could not be set via the constructor,\n",
      "    are then copied via `__copy_fill__()`, starting with the method in\n",
      "    the uppermost base class and ending with the class of the instance\n",
      "    to be copied.\n",
      "    \n",
      "    This approach solves the problem of encapsulated variables in\n",
      "    superclasses.\n",
      "    \"\"\"\n",
      "    \n",
      "    def copy(self):\n",
      "        \"\"\"\n",
      "        Create a deep copy of this object.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        copy\n",
      "            A copy of this object.\n",
      "        \"\"\"\n",
      "        clone = self.__copy_create__()\n",
      "        self.__copy_fill__(clone)\n",
      "        return clone\n",
      "    \n",
      "    def __copy_create__(self):\n",
      "        \"\"\"\n",
      "        Instantiate a new object of this class.\n",
      "        \n",
      "        Only the constructor should be called in this method.\n",
      "        All further attributes, that need to be copied are handled\n",
      "        in `__copy_fill__()`\n",
      "        \n",
      "        Do not call the `super()` method here.\n",
      "        \n",
      "        This method must be overridden, if the constructor takes\n",
      "        parameters.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        copy\n",
      "            A freshly instantiated copy of *self*.\n",
      "        \"\"\"\n",
      "        return type(self)()\n",
      "    \n",
      "    def __copy_fill__(self, clone):\n",
      "        \"\"\"\n",
      "        Copy all necessary attributes to the new object.\n",
      "        \n",
      "        Always call the `super()` method as first statement.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        clone\n",
      "            The freshly instantiated copy of *self*.\n",
      "        \"\"\"\n",
      "        pass\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "# This source code is part of the Biotite package and is distributed\n",
      "# under the 3-Clause BSD License. Please see 'LICENSE.rst' for further\n",
      "# information.\n",
      "\n",
      "__name__ = \"biotite\"\n",
      "------------------------------\n",
      "Original:\n",
      "input = \"\"\"\n",
      "c(2).\n",
      "p(1).\n",
      "a(2).\n",
      "d(2,2,1).\n",
      "okay(X):- c(X), #count{V:a(V),d(V,X,1)} = 1.\n",
      "ouch(X):- p(X), #count{V:a(V),d(V,X,1)} = 1.\n",
      "\"\"\"\n",
      "\n",
      "output = \"\"\"\n",
      "{a(2), c(2), d(2,2,1), okay(2), p(1)}\n",
      "\"\"\"\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "input = \"\"\"\n",
      "c(2).\n",
      "p(1).\n",
      "a(2).\n",
      "d(2,2,1).\n",
      "okay(X):- c(X), #count{V:a(V),d(V\n",
      "------------------------------\n",
      "Original:\n",
      "from random import shuffle as rshuffle\n",
      "from .card import Card\n",
      "\n",
      "\n",
      "class Deck:\n",
      "    \"\"\"\n",
      "    Class representing a deck. The first time we create, we seed the static \n",
      "    deck with the list of unique card integers. Each object instantiated simply\n",
      "    makes a copy of this object and shuffles it. \n",
      "    \"\"\"\n",
      "    _FULL_DECK = []\n",
      "\n",
      "    def __init__(self):\n",
      "        self.shuffle()\n",
      "\n",
      "    def shuffle(self):\n",
      "        # and then shuffle\n",
      "        self.cards = Deck.GetFullDeck()\n",
      "        rshuffle(self.cards)\n",
      "\n",
      "    def draw(self, n=1):\n",
      "        if n == 1:\n",
      "            return self.cards.pop(0)\n",
      "\n",
      "        cards = []\n",
      "        for i in range(n):\n",
      "            cards.append(self.draw())\n",
      "        return cards\n",
      "\n",
      "    def __str__(self):\n",
      "        return Card.print_pretty_cards(self.cards)\n",
      "\n",
      "    @staticmethod\n",
      "    def GetFullDeck():\n",
      "        if Deck._FULL_DECK:\n",
      "            return list(Deck._FULL_DECK)\n",
      "\n",
      "        # create the standard 52 card deck\n",
      "        for rank in Card.STR_RANKS:\n",
      "            for suit, val in Card.CHAR_SUIT_TO_INT_SUIT.items():\n",
      "                Deck._FULL_DECK.append(Card.new(rank + suit))\n",
      "\n",
      "        return list(Deck._FULL_DECK)\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "from random import shuffle as rshuffle\n",
      "from.card import Card\n",
      "\n",
      "\n",
      "class Deck:\n",
      "    \"\"\"\n",
      "    Class representing a deck. The first time we create, we seed the static \n",
      "    deck with the list of unique card integers. Each object instantiated simply\n",
      "------------------------------\n",
      "Original:\n",
      "\"\"\"\n",
      "Basic usage\n",
      "===========\n",
      "\n",
      "This example presents the basic usage of brokenaxes\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "from brokenaxes import brokenaxes\n",
      "import numpy as np\n",
      "\n",
      "fig = plt.figure(figsize=(5,2))\n",
      "bax = brokenaxes(xlims=((0, .1), (.4, .7)), ylims=((-1, .7), (.79, 1)), hspace=.05)\n",
      "x = np.linspace(0, 1, 100)\n",
      "bax.plot(x, np.sin(10 * x), label='sin')\n",
      "bax.plot(x, np.cos(10 * x), label='cos')\n",
      "bax.legend(loc=3)\n",
      "bax.set_xlabel('time')\n",
      "bax.set_ylabel('value')\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "\"\"\"\n",
      "Basic usage\n",
      "===========\n",
      "\n",
      "This example presents the basic usage of brokenaxes\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "from brokenaxes import brokenaxes\n",
      "import numpy as np\n",
      "\n",
      "fig = plt.figure(figsize=(\n",
      "------------------------------\n",
      "Original:\n",
      "# -*- coding: utf-8 -*-\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def orbit(u):\n",
      "    x,y,v_x,v_y = u\n",
      "    r=np.hypot(x,y)\n",
      "    #r= 1.521e+06\n",
      "    #M,G=1.989e+30,6.7e-11\n",
      "    M,G=20,110\n",
      "    f=G*M/r**3\n",
      "    return np.array([v_x,v_y,-f*x,-f*y])\n",
      "\n",
      "\n",
      "def RK4(f,u,dt):\n",
      "    k1=f(u)*dt\n",
      "    k2=f(u+0.5*k1)*dt\n",
      "    k3=f(u+0.5*k2)*dt\n",
      "    k4=f(u+k3)*dt\n",
      "    return u+(k1+2*k2+2*k3+k4)/6\n",
      "\n",
      "    \n",
      "def RK4_int(f,y0,tspan):\n",
      "    y=np.zeros([len(tspan),len(y0)])\n",
      "    y[0,:] =y0\n",
      "    for k in range (1,len(tspan)):\n",
      "        y[k,:] = RK4(f,y[k-1],tspan[k]-tspan[k-1])\n",
      "    return y\n",
      "\n",
      "dt=0.1\n",
      "t = np.arange(0,10,dt)\n",
      "y0=np.array([10, 0.0, 10, 10])\n",
      "\n",
      "sol_rk4=RK4_int(orbit,y0,t)\n",
      "x,y,v_x,v_y = sol_rk4.T\n",
      "plt.grid()\n",
      "plt.plot(x,y)\n",
      "plt.show()\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "# -*- coding: utf-8 -*-\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def orbit(u):\n",
      "    x,y,v_x,v_y = u\n",
      "    r=np.hypot\n",
      "------------------------------\n",
      "Original:\n",
      "import os\n",
      "\n",
      "from django.apps import apps\n",
      "from django.core.management.base import BaseCommand\n",
      "\n",
      "from factory_generator.generator import FactoryAppGenerator\n",
      "\n",
      "\n",
      "class Command(BaseCommand):\n",
      "    help = 'Create model factories for all installed apps'\n",
      "\n",
      "    def handle(self, *args, **options):\n",
      "        created_files = []\n",
      "        for app in apps.get_app_configs():\n",
      "            factory_app_generator = FactoryAppGenerator(app)\n",
      "            created_files += factory_app_generator.create_files()\n",
      "        self.stdout.write(self.style.SUCCESS('Successfully created factories:'))\n",
      "        for created_file in created_files:\n",
      "            self.stdout.write(self.style.SUCCESS('- ' + created_file))\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "import os\n",
      "\n",
      "from django.apps import apps\n",
      "from django.core.management.base import BaseCommand\n",
      "\n",
      "from factory_generator.generator import FactoryAppGenerator\n",
      "\n",
      "\n",
      "class Command(BaseCommand):\n",
      "    help = 'Create model factories for\n",
      "------------------------------\n",
      "Original:\n",
      "localhost        = \"http://localhost/\" # your local host\n",
      "database         = \"mysql://root@localhost/vaticChecker\" # server://user:pass@localhost/dbname\n",
      "min_training     = 2  # the minimum number of training videos to be considered\n",
      "recaptcha_secret = \"\" # recaptcha secret for verification\n",
      "duplicate_annotations = False # Should the server allow for duplicate annotations?\n",
      "\n",
      "import os.path\n",
      "import sys\n",
      "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
      "\n",
      "# TODO: remove on server\n",
      "import os\n",
      "os.environ['PYTHON_EGG_CACHE'] = '/tmp/apache'\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "localhost        = \"http://localhost/\" # your local host\n",
      "database         = \"mysql://root@localhost/vaticChecker\" # server://user:pass@localhost/dbname\n",
      "min_training     = 2  # the minimum number\n",
      "------------------------------\n",
      "Original:\n",
      "import pytest\n",
      "\n",
      "from pywps import Service\n",
      "from pywps.tests import assert_response_success\n",
      "\n",
      "from .common import client_for\n",
      "from malleefowl.processes import processes\n",
      "\n",
      "\n",
      "def test_wps_caps():\n",
      "    client = client_for(Service(processes=processes))\n",
      "    resp = client.get(service='wps', request='getcapabilities', version='1.0.0')\n",
      "    names = resp.xpath_text('/wps:Capabilities'\n",
      "                            '/wps:ProcessOfferings'\n",
      "                            '/wps:Process'\n",
      "                            '/ows:Identifier')\n",
      "    assert sorted(names.split()) == [\n",
      "        'download',\n",
      "        'esgsearch',\n",
      "        'thredds_download',\n",
      "        'workflow'\n",
      "    ]\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "import pytest\n",
      "\n",
      "from pywps import Service\n",
      "from pywps.tests import assert_response_success\n",
      "\n",
      "from.common import client_for\n",
      "from malleefowl.processes import processes\n",
      "\n",
      "\n",
      "def test_wps_\n",
      "------------------------------\n",
      "Original:\n",
      "from setuptools import setup\n",
      "\n",
      "__author__ = \"Alex Laird\"\n",
      "__copyright__ = \"Copyright 2019, Alex Laird\"\n",
      "__version__ = \"1.4.0\"\n",
      "\n",
      "with open(\"README.md\", \"r\") as f:\n",
      "    long_description = f.read()\n",
      "\n",
      "setup(\n",
      "    name=\"pyngrok\",\n",
      "    version=__version__,\n",
      "    packages=[\"pyngrok\"],\n",
      "    python_requires=\">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*\",\n",
      "    install_requires=[\n",
      "        \"future\",\n",
      "        \"pyyaml\"\n",
      "    ],\n",
      "    entry_points=\"\"\"\n",
      "        [console_scripts]\n",
      "        ngrok=pyngrok.ngrok:run\n",
      "    \"\"\",\n",
      "    description=\"A Python wrapper for Ngrok.\",\n",
      "    long_description=long_description,\n",
      "    long_description_content_type=\"text/markdown\",\n",
      "    author=\"Alex Laird\",\n",
      "    author_email=\"contact@alexlaird.com\",\n",
      "    url=\"https://github.com/alexdlaird/pyngrok\",\n",
      "    download_url=\"https://github.com/alexdlaird/pyngrok/archive/{}.tar.gz\".format(__version__),\n",
      "    keywords=[\"ngrok\", \"tunnel\", \"tunneling\", \"webhook\", \"localhost\"],\n",
      "    license=\"MIT\",\n",
      "    classifiers=[\n",
      "        \"Programming Language :: Python :: 2.7\",\n",
      "        \"Programming Language :: Python :: 3.4\",\n",
      "        \"Programming Language :: Python :: 3.5\",\n",
      "        \"Programming Language :: Python :: 3.6\",\n",
      "        \"Programming Language :: Python :: 3.7\",\n",
      "        \"Programming Language :: Python :: Implementation :: CPython\",\n",
      "        \"Programming Language :: Python :: Implementation :: PyPy\",\n",
      "        \"Topic :: Software Development :: Libraries :: Python Modules\",\n",
      "        \"Environment :: Console\",\n",
      "        \"Environment :: Web Environment\",\n",
      "        \"Intended Audience :: Developers\",\n",
      "        \"Intended Audience :: Education\",\n",
      "        \"Development Status :: 5 - Production/Stable\",\n",
      "        \"License :: OSI Approved :: MIT License\",\n",
      "        \"Operating System :: MacOS\",\n",
      "        \"Operating System :: Microsoft :: Windows\",\n",
      "        \"Operating System :: POSIX\",\n",
      "        \"Operating System :: Unix\"\n",
      "    ]\n",
      ")\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "from setuptools import setup\n",
      "\n",
      "__author__ = \"Alex Laird\"\n",
      "__copyright__ = \"Copyright 2019, Alex Laird\"\n",
      "__version__ = \"1.4.0\"\n",
      "\n",
      "with open\n",
      "------------------------------\n",
      "Original:\n",
      "#!/usr/bin/env python3\n",
      "\n",
      "import kfp.dsl as dsl\n",
      "import kfp.gcp as gcp\n",
      "\n",
      "# Pipeline input variables.\n",
      "KUBECTL_IMAGE = \"gcr.io/mcas-195423/trackml_master_kfp_kubectl\"\n",
      "KUBECTL_IMAGE_VERSION = \"1\"\n",
      "TRACKML_IMAGE = \"gcr.io/mcas-195423/trackml_master_trackml\"\n",
      "TRACKML_IMAGE_VERSION = \"1\"\n",
      "\n",
      "def train_op():\n",
      "  return dsl.ContainerOp(\n",
      "    name='train',\n",
      "    image=\"{}:{}\".format(TRACKML_IMAGE, TRACKML_IMAGE_VERSION),\n",
      "    command=[\"python\"],\n",
      "    arguments=[\"train.py\"],\n",
      "  ).apply(gcp.use_gcp_secret()\n",
      "  )#.set_gpu_limit(1)\n",
      "\n",
      "def serve_op():\n",
      "  return dsl.ContainerOp(\n",
      "    name='serve',\n",
      "    image=\"{}:{}\".format(KUBECTL_IMAGE, KUBECTL_IMAGE_VERSION),\n",
      "    arguments=[\n",
      "      \"/src/set_kubectl.sh\",\n",
      "      \"--namespace\", \"kubeflow\",\n",
      "      \"--command\", \"apply -f /src/k8s/serve.yaml\",\n",
      "    ]\n",
      "  ).apply(gcp.use_gcp_secret())\n",
      "\n",
      "def resultsgen_op():\n",
      "  return dsl.ContainerOp(\n",
      "    name='resultsgen',\n",
      "    image=\"{}:{}\".format(TRACKML_IMAGE, TRACKML_IMAGE_VERSION),\n",
      "    command=[\"python\"],\n",
      "    arguments=[\"resultsgen.py\"],\n",
      "  ).apply(gcp.use_gcp_secret())\n",
      "\n",
      "@dsl.pipeline(\n",
      "  name='trackml',\n",
      "  description='A pipeline that predicts particle tracks'\n",
      ")\n",
      "def trackml():\n",
      "  train = train_op()\n",
      "\n",
      "  serve = serve_op()\n",
      "  serve.after(train)\n",
      "\n",
      "  resultsgen = resultsgen_op()\n",
      "  resultsgen.after(serve)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "  import kfp.compiler as compiler\n",
      "  compiler.Compiler().compile(trackml, __file__ + '.tar.gz')\n",
      "\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "#!/usr/bin/env python3\n",
      "\n",
      "import kfp.dsl as dsl\n",
      "import kfp.gcp as gcp\n",
      "\n",
      "# Pipeline input variables.\n",
      "KUBECTL_IMAGE = \"gcr.io/mcas-\n",
      "------------------------------\n",
      "Original:\n",
      "from setuptools import setup\n",
      "\n",
      "# create __version__\n",
      "exec(open('./_version.py').read())\n",
      "\n",
      "setup(\n",
      "    name=\"notedown\",\n",
      "    version=__version__,\n",
      "    description=\"Convert markdown to IPython notebook.\",\n",
      "    author=\"Aaron O'Leary\",\n",
      "    author_email='dev@aaren.me',\n",
      "    url='http://github.com/aaren/notedown',\n",
      "    install_requires=['ipython', ],\n",
      "    entry_points={\n",
      "        'console_scripts': [\n",
      "            'notedown = notedown:cli',\n",
      "        ],\n",
      "    }\n",
      ")\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "from setuptools import setup\n",
      "\n",
      "# create __version__\n",
      "exec(open('./_version.py').read())\n",
      "\n",
      "setup(\n",
      "    name=\"notedown\",\n",
      "    version=__version__,\n",
      "    description=\"Convert markdown to IPython notebook.\",\n",
      "   \n",
      "------------------------------\n",
      "Original:\n",
      "from gensim import corpora, models, similarities, matutils,utils\n",
      "from gensim.models import KeyedVectors\n",
      "import numpy as np\n",
      "\n",
      "#Word2vec Experiment\n",
      "testString = ['PAST_MEDICAL_HISTORY','PAST_SURGICAL_HISTORY','PHYSICAL_EXAMINATION']\n",
      "'''\n",
      "word_vectors = KeyedVectors.load_word2vec_format('~/Downloads/GoogleNews-vectors-negative300.bin', binary=True)\n",
      "#model.save(\"file.txt\")\n",
      "print word_vectors.most_similar(positive=['woman', 'king'], negative=['man'])\n",
      "print \"******************************************************\"\n",
      "print word_vectors.similarity('woman', 'man')\n",
      "#print  word_vectors.most_similar(positive=['san_francisco'])\n",
      "print  word_vectors.most_similar(positive=['SURGICAL'])\n",
      "\n",
      "#word_vectors.similarity(testString[0],testString[1])\n",
      "\n",
      "'''\n",
      "a=[1,4,3,6,3,6]\n",
      "print a[:-1]\n",
      "#print zip(a[:-1],a[1:])\n",
      "print np.random.randn(3, 2)\n",
      "\n",
      "XXXXXXXXXX\n",
      "Prediction:\n",
      "from gensim import corpora, models, similarities, matutils,utils\n",
      "from gensim.models import KeyedVectors\n",
      "import numpy as np\n",
      "\n",
      "#Word2vec Experiment\n",
      "testString = ['PAST_MEDICAL\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,el in enumerate(tokenizer.batch_decode(inputs)):\n",
    "    print(\"Original:\")\n",
    "    print(df.iloc[i][\"content\"])\n",
    "    print(\"X\"*10)\n",
    "    print(\"Prediction:\")\n",
    "    print(el)\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from django.contrib import admin\n",
      "from.models import SearchResult\n",
      "\n",
      "# Register your models here.\n",
      "class SearchResultAdmin(admin.ModelAdmin):\n",
      "    fields = [\"query\", \"heading\", \"url\", \"text\"]\n",
      "\n",
      "admine = 0\n",
      "for i in range(1, 1000000):\n",
      "    if i % 3 == 0 or i % 5 == 0:\n",
      "        e += i\n",
      "print(e)\n",
      "kagemeka/atcoder-submissions\n",
      "# 2520 is the smallest number that can be divided by each of the numbers from 1 to 10 without any remainder.\n",
      "# What is the smallest positive number that is evenly divisible by all of the numbers from 1 to 20?\n",
      "\n",
      "# 1から10までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の倍数を全て求める\n",
      "# 1から20までの数の\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n",
    "print(tokenizer.batch_decode(output, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "prefix_size = 50\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, )\n",
    "\n",
    "inputs = tokenizer.encode(df.iloc[i][\"content\"], return_tensors=\"pt\").to(device)\n",
    "# inputs[:,prefix_size:] = 0\n",
    "# inputs[\"attention_mask\"][prefix_size:] = 0\n",
    "# inputs[\"input_ids\"\n",
    "output = model.generate(inputs[:,:prefix_size], max_new_tokens=512,\n",
    "                        do_sample=False,\n",
    "                        )\n",
    "\n",
    "\n",
    "# output = model.generate(inputs[:,:-prefix_size], max_new_tokens=512,\n",
    "#                         temperature=0.7, do_sample=True, top_p=0.95, top_k=40,\n",
    "#                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "batch_size = 2\n",
    "prefix_size = 50\n",
    "\n",
    "i = 0\n",
    "\n",
    "batch = list(df.iloc[:batch_size][\"content\"].values)\n",
    "inputs = tokenizer(batch, return_tensors=\"pt\", padding=True).to(device)    \n",
    "\n",
    "inputs = inputs[\"input_ids\"][:,:prefix_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 50])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(inputs, max_new_tokens=512,\n",
    "                        do_sample=False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 92])\n",
      "class Solution:\n",
      "    def finalPrices(self, prices: List[int]) -> List[int]:\n",
      "        res = []\n",
      "        for i in range(len(prices)):\n",
      "            for j in range(i+1,len(prices)):\n",
      "                if prices[j] <= prices[i]:\n",
      "                    res.append(prices[i]-prices[j])\n",
      "                    break\n",
      "            else:\n",
      "                res.append(prices[i])\n",
      "        return res\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "\n",
    "output = model.generate(inputs[i].unsqueeze(0), max_new_tokens=512,\n",
    "                        do_sample=False,\n",
    "                        )\n",
    "\n",
    "print(output.shape)\n",
    "\n",
    "print(tokenizer.batch_decode(output)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 92])\n",
      "class Solution:\n",
      "    def finalPrices(self, prices: List[int]) -> List[int]:\n",
      "        res = []\n",
      "        for i in range(len(prices)):\n",
      "            for j in range(i+1,len(prices)):\n",
      "                if prices[j] <= prices[i]:\n",
      "                    res.append(prices[i]-prices[j])\n",
      "                    break\n",
      "            else:\n",
      "                res.append(prices[i])\n",
      "        return res\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(inputs, max_new_tokens=512,\n",
    "                        do_sample=False,\n",
    "                        )\n",
    "\n",
    "print(output.shape)\n",
    "\n",
    "print(tokenizer.batch_decode(output, skip_special_tokens=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from django.contrib import admin\n",
      "from.models import SearchResult\n",
      "\n",
      "# Register your models here.\n",
      "class SearchResultAdmin(admin.ModelAdmin):\n",
      "    fields = [\"query\", \"heading\", \"url\", \"text\"]\n",
      "\n",
      "admin\n",
      "------------------------------\n",
      "class Solution:\n",
      "    def finalPrices(self, prices: List[int]) -> List[int]:\n",
      "        res = []\n",
      "        for i in range(len(prices)):\n",
      "            for j in range(i+1,len(prices)):\n",
      "               \n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for el in tokenizer.batch_decode(inputs):\n",
    "    print(el)\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Solution:\n",
      "    def finalPrices(self, prices: List[int]) -> List[int]:\n",
      "        res = []\n",
      "        for i in range(len(prices)):\n",
      "            for j in range(i+1,len(prices)):\n",
      "                if prices[j] <= prices[i]:\n",
      "                    res.append(prices[i]-prices[j])\n",
      "                    break\n",
      "            else:\n",
      "                res.append(prices[i])\n",
      "        return res\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(output, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[[ 2.1740,  2.6138,  1.9444,  ..., -2.6618, -3.2065, -3.0658],\n",
       "         [ 3.3816,  2.8832,  2.8859,  ..., -2.3122, -2.8361, -3.1043],\n",
       "         [-2.4919,  1.9409, -2.9147,  ..., -1.0440, -5.6912, -4.1187],\n",
       "         ...,\n",
       "         [ 2.0382,  3.6103,  3.7609,  ..., -2.2791, -2.5053, -4.7208],\n",
       "         [ 2.0515,  3.4067,  3.7768,  ..., -2.1654, -2.2264, -4.2897],\n",
       "         [ 2.0355,  3.4796,  3.7269,  ..., -2.1208, -2.2250, -4.3397]],\n",
       "\n",
       "        [[ 2.1740,  2.6138,  1.9444,  ..., -2.6618, -3.2065, -3.0658],\n",
       "         [ 3.3816,  2.8832,  2.8859,  ..., -2.3122, -2.8361, -3.1043],\n",
       "         [-2.4919,  1.9409, -2.9147,  ..., -1.0440, -5.6912, -4.1187],\n",
       "         ...,\n",
       "         [ 2.0382,  3.6103,  3.7609,  ..., -2.2791, -2.5053, -4.7208],\n",
       "         [ 2.0515,  3.4067,  3.7768,  ..., -2.1654, -2.2264, -4.2897],\n",
       "         [ 2.0355,  3.4796,  3.7269,  ..., -2.1208, -2.2250, -4.3397]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>), past_key_values=[tensor([[[ 9.5340e+00,  4.6970e-01, -2.6941e-01,  ...,  4.9366e-02,\n",
       "          -2.3066e-02,  3.7960e-02],\n",
       "         [ 6.6267e-01,  2.1218e+00, -2.1361e+00,  ..., -2.3648e-02,\n",
       "          -4.6984e-02, -2.2412e-02],\n",
       "         [-6.4907e+00,  8.1114e-01, -8.6830e-01,  ...,  6.0570e-02,\n",
       "          -4.8586e-02, -1.1418e-02],\n",
       "         ...,\n",
       "         [ 1.8390e+00, -4.3918e-02, -5.9050e-01,  ..., -5.7800e-02,\n",
       "          -9.0181e-02, -2.3194e-03],\n",
       "         [ 5.2138e+00, -2.9437e-01, -2.8836e+00,  ...,  5.6439e-02,\n",
       "          -1.2196e-01,  2.8143e-01],\n",
       "         [ 3.3288e+00,  4.3952e-01, -2.4029e+00,  ...,  9.1834e-03,\n",
       "           1.5157e-01, -1.3031e-01]],\n",
       "\n",
       "        [[ 9.5340e+00,  4.6970e-01, -2.6941e-01,  ...,  4.9366e-02,\n",
       "          -2.3066e-02,  3.7960e-02],\n",
       "         [ 6.6267e-01,  2.1218e+00, -2.1361e+00,  ..., -2.3648e-02,\n",
       "          -4.6984e-02, -2.2412e-02],\n",
       "         [-6.4907e+00,  8.1114e-01, -8.6830e-01,  ...,  6.0570e-02,\n",
       "          -4.8586e-02, -1.1418e-02],\n",
       "         ...,\n",
       "         [ 1.8390e+00, -4.3918e-02, -5.9050e-01,  ..., -5.7800e-02,\n",
       "          -9.0181e-02, -2.3194e-03],\n",
       "         [ 5.2138e+00, -2.9437e-01, -2.8836e+00,  ...,  5.6439e-02,\n",
       "          -1.2196e-01,  2.8143e-01],\n",
       "         [ 3.3288e+00,  4.3952e-01, -2.4029e+00,  ...,  9.1834e-03,\n",
       "           1.5157e-01, -1.3031e-01]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-4.7277e-01, -3.8757e-01,  2.9086e-02,  ...,  2.0120e-03,\n",
       "          -6.3727e-03, -1.2015e-03],\n",
       "         [-5.0852e-01, -2.7920e-01,  3.8234e-01,  ..., -4.9742e-03,\n",
       "          -2.0288e-02,  3.2486e-04],\n",
       "         [-1.4048e+00, -7.9776e-01, -1.0039e-01,  ...,  1.1268e-01,\n",
       "          -2.4156e-02,  7.1890e-02],\n",
       "         ...,\n",
       "         [-1.7184e+00,  1.5942e+00,  2.2859e+00,  ...,  7.1198e-02,\n",
       "           1.7987e-04,  1.9272e-01],\n",
       "         [-1.8927e+00,  1.8660e+00,  2.4496e+00,  ...,  6.5787e-02,\n",
       "          -4.5166e-04,  1.8924e-01],\n",
       "         [-1.6488e+00,  1.8066e+00,  2.4324e+00,  ...,  8.0727e-02,\n",
       "           7.0588e-03,  2.0518e-01]],\n",
       "\n",
       "        [[-4.7277e-01, -3.8757e-01,  2.9086e-02,  ...,  2.0120e-03,\n",
       "          -6.3727e-03, -1.2015e-03],\n",
       "         [-5.0852e-01, -2.7920e-01,  3.8234e-01,  ..., -4.9742e-03,\n",
       "          -2.0288e-02,  3.2486e-04],\n",
       "         [-1.4048e+00, -7.9776e-01, -1.0039e-01,  ...,  1.1268e-01,\n",
       "          -2.4156e-02,  7.1890e-02],\n",
       "         ...,\n",
       "         [-1.7184e+00,  1.5942e+00,  2.2859e+00,  ...,  7.1198e-02,\n",
       "           1.7987e-04,  1.9272e-01],\n",
       "         [-1.8927e+00,  1.8660e+00,  2.4496e+00,  ...,  6.5787e-02,\n",
       "          -4.5166e-04,  1.8924e-01],\n",
       "         [-1.6488e+00,  1.8066e+00,  2.4324e+00,  ...,  8.0727e-02,\n",
       "           7.0588e-03,  2.0518e-01]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 2.4106e-01,  6.8942e-01, -1.6485e+00,  ..., -6.0610e-03,\n",
       "           1.5363e-03, -3.7078e-03],\n",
       "         [ 1.9393e-01,  6.1866e-01, -1.4842e+00,  ..., -1.5229e-02,\n",
       "          -2.9132e-03,  7.3428e-03],\n",
       "         [-2.7094e-01, -1.1865e+00,  2.6965e+00,  ..., -3.0682e-02,\n",
       "          -7.6698e-02,  9.2790e-02],\n",
       "         ...,\n",
       "         [ 1.7227e+00, -1.5538e-01,  4.5802e+00,  ..., -7.0543e-02,\n",
       "          -1.2881e-01,  1.0696e-01],\n",
       "         [ 1.9988e+00,  1.2280e-02,  4.6855e+00,  ..., -7.1108e-02,\n",
       "          -1.5664e-01,  1.1184e-01],\n",
       "         [ 1.9372e+00,  7.8326e-03,  4.7428e+00,  ..., -7.6852e-02,\n",
       "          -1.4380e-01,  1.1148e-01]],\n",
       "\n",
       "        [[ 2.4106e-01,  6.8942e-01, -1.6485e+00,  ..., -6.0610e-03,\n",
       "           1.5363e-03, -3.7078e-03],\n",
       "         [ 1.9393e-01,  6.1866e-01, -1.4842e+00,  ..., -1.5229e-02,\n",
       "          -2.9132e-03,  7.3428e-03],\n",
       "         [-2.7094e-01, -1.1865e+00,  2.6965e+00,  ..., -3.0682e-02,\n",
       "          -7.6698e-02,  9.2790e-02],\n",
       "         ...,\n",
       "         [ 1.7227e+00, -1.5538e-01,  4.5802e+00,  ..., -7.0543e-02,\n",
       "          -1.2881e-01,  1.0696e-01],\n",
       "         [ 1.9988e+00,  1.2280e-02,  4.6855e+00,  ..., -7.1108e-02,\n",
       "          -1.5664e-01,  1.1184e-01],\n",
       "         [ 1.9372e+00,  7.8326e-03,  4.7428e+00,  ..., -7.6852e-02,\n",
       "          -1.4380e-01,  1.1148e-01]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-3.8059e-01, -6.1891e-01,  4.9788e-01,  ..., -1.7744e-03,\n",
       "          -5.6171e-04, -2.6998e-03],\n",
       "         [-6.6629e-02, -2.2419e-01,  4.6258e-01,  ..., -2.4415e-03,\n",
       "           4.0343e-03,  9.5004e-05],\n",
       "         [-9.0023e-01, -1.1038e-01, -3.6436e+00,  ...,  6.4555e-02,\n",
       "           2.2887e-02,  9.0459e-02],\n",
       "         ...,\n",
       "         [-5.5472e-01,  1.9207e+00, -1.6782e+00,  ..., -1.0085e-01,\n",
       "           1.0244e-01,  2.1574e-02],\n",
       "         [-1.7422e-01,  1.2737e+00, -8.2254e-01,  ..., -8.6248e-02,\n",
       "           3.5234e-02,  2.1937e-02],\n",
       "         [-2.2057e-01,  1.3577e+00, -9.3430e-01,  ..., -8.8100e-02,\n",
       "           4.3539e-02,  2.4845e-02]],\n",
       "\n",
       "        [[-3.8059e-01, -6.1891e-01,  4.9788e-01,  ..., -1.7744e-03,\n",
       "          -5.6171e-04, -2.6998e-03],\n",
       "         [-6.6629e-02, -2.2419e-01,  4.6258e-01,  ..., -2.4415e-03,\n",
       "           4.0343e-03,  9.5004e-05],\n",
       "         [-9.0023e-01, -1.1038e-01, -3.6436e+00,  ...,  6.4555e-02,\n",
       "           2.2887e-02,  9.0459e-02],\n",
       "         ...,\n",
       "         [-5.5472e-01,  1.9207e+00, -1.6782e+00,  ..., -1.0085e-01,\n",
       "           1.0244e-01,  2.1574e-02],\n",
       "         [-1.7422e-01,  1.2737e+00, -8.2254e-01,  ..., -8.6248e-02,\n",
       "           3.5234e-02,  2.1937e-02],\n",
       "         [-2.2057e-01,  1.3577e+00, -9.3430e-01,  ..., -8.8100e-02,\n",
       "           4.3539e-02,  2.4845e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-4.2419e-03,  1.1030e+00,  5.2137e-01,  ..., -2.6181e-03,\n",
       "          -1.6207e-06,  4.1876e-03],\n",
       "         [ 2.9284e-01,  3.3205e-01,  2.5101e-01,  ..., -8.9294e-03,\n",
       "          -6.1420e-03,  9.9237e-03],\n",
       "         [-1.8410e-01,  7.4421e-01,  2.0522e+00,  ...,  2.1022e-01,\n",
       "           2.0528e-01,  1.7528e-01],\n",
       "         ...,\n",
       "         [ 2.0664e-01, -2.5722e-01, -7.5111e-02,  ...,  1.7011e-01,\n",
       "           6.1468e-02,  4.6908e-02],\n",
       "         [ 5.0906e-01,  1.3879e-01,  1.4987e-01,  ...,  1.0808e-01,\n",
       "           2.8645e-02,  4.3585e-02],\n",
       "         [ 4.5966e-01,  8.2955e-02,  1.0131e-01,  ...,  1.2107e-01,\n",
       "           3.4475e-02,  4.5297e-02]],\n",
       "\n",
       "        [[-4.2419e-03,  1.1030e+00,  5.2137e-01,  ..., -2.6181e-03,\n",
       "          -1.6207e-06,  4.1876e-03],\n",
       "         [ 2.9284e-01,  3.3205e-01,  2.5101e-01,  ..., -8.9294e-03,\n",
       "          -6.1420e-03,  9.9237e-03],\n",
       "         [-1.8410e-01,  7.4421e-01,  2.0522e+00,  ...,  2.1022e-01,\n",
       "           2.0528e-01,  1.7528e-01],\n",
       "         ...,\n",
       "         [ 2.0664e-01, -2.5722e-01, -7.5111e-02,  ...,  1.7011e-01,\n",
       "           6.1468e-02,  4.6908e-02],\n",
       "         [ 5.0906e-01,  1.3879e-01,  1.4987e-01,  ...,  1.0808e-01,\n",
       "           2.8645e-02,  4.3585e-02],\n",
       "         [ 4.5966e-01,  8.2955e-02,  1.0131e-01,  ...,  1.2107e-01,\n",
       "           3.4475e-02,  4.5297e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 2.7876e-01,  2.3421e-01,  5.2599e-01,  ..., -4.2435e-03,\n",
       "          -6.1152e-03, -2.3676e-05],\n",
       "         [-6.7402e-01, -2.1303e-01,  3.7253e-01,  ..., -8.1245e-03,\n",
       "           1.9711e-03,  2.1477e-02],\n",
       "         [-1.5209e+00,  2.3361e-02, -2.4645e+00,  ...,  5.0897e-02,\n",
       "          -5.4727e-02,  1.3166e-01],\n",
       "         ...,\n",
       "         [ 7.9457e-01,  3.4423e-01,  7.9511e-01,  ...,  3.2208e-02,\n",
       "          -5.5611e-02,  4.3072e-02],\n",
       "         [ 1.0324e+00,  5.8061e-02,  8.7996e-01,  ...,  2.4670e-02,\n",
       "          -3.7053e-02,  3.6479e-02],\n",
       "         [ 1.0011e+00,  1.1566e-01,  8.7076e-01,  ...,  2.5231e-02,\n",
       "          -4.0024e-02,  3.7320e-02]],\n",
       "\n",
       "        [[ 2.7876e-01,  2.3421e-01,  5.2599e-01,  ..., -4.2435e-03,\n",
       "          -6.1152e-03, -2.3676e-05],\n",
       "         [-6.7402e-01, -2.1303e-01,  3.7253e-01,  ..., -8.1245e-03,\n",
       "           1.9711e-03,  2.1477e-02],\n",
       "         [-1.5209e+00,  2.3361e-02, -2.4645e+00,  ...,  5.0897e-02,\n",
       "          -5.4727e-02,  1.3166e-01],\n",
       "         ...,\n",
       "         [ 7.9457e-01,  3.4423e-01,  7.9511e-01,  ...,  3.2208e-02,\n",
       "          -5.5611e-02,  4.3072e-02],\n",
       "         [ 1.0324e+00,  5.8061e-02,  8.7996e-01,  ...,  2.4670e-02,\n",
       "          -3.7053e-02,  3.6479e-02],\n",
       "         [ 1.0011e+00,  1.1566e-01,  8.7076e-01,  ...,  2.5231e-02,\n",
       "          -4.0024e-02,  3.7320e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-2.9627e-02,  2.5569e-01,  3.7994e-01,  ..., -1.2097e-03,\n",
       "           2.4642e-03, -1.0389e-02],\n",
       "         [-4.1201e-01,  8.9251e-02, -1.3528e+00,  ...,  4.3224e-02,\n",
       "           6.4634e-03, -6.9656e-02],\n",
       "         [-2.2406e-01,  2.3514e-01, -6.2038e-01,  ...,  1.0138e-01,\n",
       "          -2.8936e-01,  2.5704e-03],\n",
       "         ...,\n",
       "         [-4.9484e-01, -6.0194e-01, -3.6896e-01,  ...,  8.8048e-02,\n",
       "          -1.4769e-01,  4.6158e-02],\n",
       "         [-5.8616e-01, -4.8194e-01, -2.5552e-01,  ...,  4.6646e-02,\n",
       "          -1.0499e-01,  2.6599e-02],\n",
       "         [-5.6388e-01, -4.9749e-01, -2.7588e-01,  ...,  5.4131e-02,\n",
       "          -1.1199e-01,  3.3103e-02]],\n",
       "\n",
       "        [[-2.9627e-02,  2.5569e-01,  3.7994e-01,  ..., -1.2097e-03,\n",
       "           2.4642e-03, -1.0389e-02],\n",
       "         [-4.1201e-01,  8.9251e-02, -1.3528e+00,  ...,  4.3224e-02,\n",
       "           6.4634e-03, -6.9656e-02],\n",
       "         [-2.2406e-01,  2.3514e-01, -6.2038e-01,  ...,  1.0138e-01,\n",
       "          -2.8936e-01,  2.5704e-03],\n",
       "         ...,\n",
       "         [-4.9484e-01, -6.0194e-01, -3.6896e-01,  ...,  8.8048e-02,\n",
       "          -1.4769e-01,  4.6158e-02],\n",
       "         [-5.8616e-01, -4.8194e-01, -2.5552e-01,  ...,  4.6646e-02,\n",
       "          -1.0499e-01,  2.6599e-02],\n",
       "         [-5.6388e-01, -4.9749e-01, -2.7588e-01,  ...,  5.4131e-02,\n",
       "          -1.1199e-01,  3.3103e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 7.2715e-02,  8.3163e-02, -2.8392e-01,  ...,  1.1155e-03,\n",
       "          -9.3059e-05, -1.2656e-03],\n",
       "         [-6.6249e-02, -3.9888e-01, -8.0956e-02,  ..., -3.5917e-02,\n",
       "          -3.7117e-02,  8.3928e-03],\n",
       "         [-1.1690e-01, -3.2471e-01,  2.7292e-01,  ...,  5.8258e-02,\n",
       "           2.9705e-02, -1.6880e-01],\n",
       "         ...,\n",
       "         [ 4.6375e-01,  7.1163e-01, -1.4657e+00,  ..., -7.8906e-02,\n",
       "          -1.3391e-01,  1.5316e-01],\n",
       "         [ 3.4351e-01,  5.3969e-01, -1.3477e+00,  ..., -5.4393e-02,\n",
       "          -1.0006e-01,  1.2684e-01],\n",
       "         [ 3.6878e-01,  5.7178e-01, -1.3899e+00,  ..., -5.9065e-02,\n",
       "          -1.0420e-01,  1.3060e-01]],\n",
       "\n",
       "        [[ 7.2715e-02,  8.3163e-02, -2.8392e-01,  ...,  1.1155e-03,\n",
       "          -9.3059e-05, -1.2656e-03],\n",
       "         [-6.6249e-02, -3.9888e-01, -8.0956e-02,  ..., -3.5917e-02,\n",
       "          -3.7117e-02,  8.3928e-03],\n",
       "         [-1.1690e-01, -3.2471e-01,  2.7292e-01,  ...,  5.8258e-02,\n",
       "           2.9705e-02, -1.6880e-01],\n",
       "         ...,\n",
       "         [ 4.6375e-01,  7.1163e-01, -1.4657e+00,  ..., -7.8906e-02,\n",
       "          -1.3391e-01,  1.5316e-01],\n",
       "         [ 3.4351e-01,  5.3969e-01, -1.3477e+00,  ..., -5.4393e-02,\n",
       "          -1.0006e-01,  1.2684e-01],\n",
       "         [ 3.6878e-01,  5.7178e-01, -1.3899e+00,  ..., -5.9065e-02,\n",
       "          -1.0420e-01,  1.3060e-01]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-1.0807e+00, -2.5068e-01, -1.6647e-01,  ..., -1.5531e-02,\n",
       "          -3.3155e-03, -1.3031e-03],\n",
       "         [-1.0592e+00, -9.0553e-01, -3.3734e-01,  ..., -7.6878e-02,\n",
       "          -1.3168e-02, -1.2921e-02],\n",
       "         [ 8.1546e-01,  3.9812e+00,  2.2509e+00,  ...,  1.0479e-02,\n",
       "           1.7395e-01,  1.7837e-01],\n",
       "         ...,\n",
       "         [-1.9260e+00, -1.1161e+00,  4.8438e-01,  ..., -3.6839e-03,\n",
       "           9.2041e-02, -5.2017e-02],\n",
       "         [-1.9607e+00, -9.1977e-01,  4.0912e-01,  ..., -1.0770e-02,\n",
       "           6.7796e-02, -4.6831e-02],\n",
       "         [-1.9586e+00, -9.6165e-01,  4.1547e-01,  ..., -9.8047e-03,\n",
       "           7.1916e-02, -4.7425e-02]],\n",
       "\n",
       "        [[-1.0807e+00, -2.5068e-01, -1.6647e-01,  ..., -1.5531e-02,\n",
       "          -3.3155e-03, -1.3031e-03],\n",
       "         [-1.0592e+00, -9.0553e-01, -3.3734e-01,  ..., -7.6878e-02,\n",
       "          -1.3168e-02, -1.2921e-02],\n",
       "         [ 8.1546e-01,  3.9812e+00,  2.2509e+00,  ...,  1.0479e-02,\n",
       "           1.7395e-01,  1.7837e-01],\n",
       "         ...,\n",
       "         [-1.9260e+00, -1.1161e+00,  4.8438e-01,  ..., -3.6839e-03,\n",
       "           9.2041e-02, -5.2017e-02],\n",
       "         [-1.9607e+00, -9.1977e-01,  4.0912e-01,  ..., -1.0770e-02,\n",
       "           6.7796e-02, -4.6831e-02],\n",
       "         [-1.9586e+00, -9.6165e-01,  4.1547e-01,  ..., -9.8047e-03,\n",
       "           7.1916e-02, -4.7425e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-4.0472e-01, -2.0571e-01,  2.4609e+00,  ..., -5.1338e-03,\n",
       "           2.3879e-03, -8.6056e-03],\n",
       "         [ 3.8650e-01,  1.5949e-01,  1.8048e+00,  ..., -1.0052e-02,\n",
       "           6.2624e-02, -9.6578e-02],\n",
       "         [ 5.2769e-01,  1.1193e+00, -3.7562e+00,  ..., -5.7068e-02,\n",
       "           6.4939e-01, -1.1602e-01],\n",
       "         ...,\n",
       "         [ 2.8081e-01,  4.9436e-02,  2.0031e+00,  ...,  4.6444e-02,\n",
       "           3.1628e-02, -2.5849e-02],\n",
       "         [ 8.8381e-02, -1.1518e-01,  1.9413e+00,  ...,  4.0675e-02,\n",
       "           1.5478e-02, -3.4425e-02],\n",
       "         [ 1.2873e-01, -9.0141e-02,  1.9436e+00,  ...,  4.0684e-02,\n",
       "           1.6897e-02, -3.1778e-02]],\n",
       "\n",
       "        [[-4.0472e-01, -2.0571e-01,  2.4609e+00,  ..., -5.1338e-03,\n",
       "           2.3879e-03, -8.6056e-03],\n",
       "         [ 3.8650e-01,  1.5949e-01,  1.8048e+00,  ..., -1.0052e-02,\n",
       "           6.2624e-02, -9.6578e-02],\n",
       "         [ 5.2769e-01,  1.1193e+00, -3.7562e+00,  ..., -5.7068e-02,\n",
       "           6.4939e-01, -1.1602e-01],\n",
       "         ...,\n",
       "         [ 2.8081e-01,  4.9436e-02,  2.0031e+00,  ...,  4.6444e-02,\n",
       "           3.1628e-02, -2.5849e-02],\n",
       "         [ 8.8381e-02, -1.1518e-01,  1.9413e+00,  ...,  4.0675e-02,\n",
       "           1.5478e-02, -3.4425e-02],\n",
       "         [ 1.2873e-01, -9.0141e-02,  1.9436e+00,  ...,  4.0684e-02,\n",
       "           1.6897e-02, -3.1778e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 3.5960e-02,  1.4612e+00,  1.3110e-01,  ..., -1.0122e-03,\n",
       "          -1.0369e-02,  5.2384e-03],\n",
       "         [-5.7683e-01, -3.8336e-02,  6.2659e-01,  ...,  2.3903e-02,\n",
       "          -8.8716e-02,  6.6621e-02],\n",
       "         [-1.6383e-01,  1.1894e+00, -4.2668e-01,  ..., -6.6377e-02,\n",
       "          -1.1499e-01,  1.4921e-01],\n",
       "         ...,\n",
       "         [-3.8638e-01,  6.8216e-03,  1.1716e+00,  ...,  3.7961e-03,\n",
       "           1.5180e-02, -6.4815e-02],\n",
       "         [-3.6643e-01,  1.9216e-01,  9.5022e-01,  ...,  3.5738e-02,\n",
       "           2.4607e-02, -5.0703e-02],\n",
       "         [-3.7058e-01,  1.5777e-01,  9.9327e-01,  ...,  3.2743e-02,\n",
       "           2.3196e-02, -5.3202e-02]],\n",
       "\n",
       "        [[ 3.5960e-02,  1.4612e+00,  1.3110e-01,  ..., -1.0122e-03,\n",
       "          -1.0369e-02,  5.2384e-03],\n",
       "         [-5.7683e-01, -3.8336e-02,  6.2659e-01,  ...,  2.3903e-02,\n",
       "          -8.8716e-02,  6.6621e-02],\n",
       "         [-1.6383e-01,  1.1894e+00, -4.2668e-01,  ..., -6.6377e-02,\n",
       "          -1.1499e-01,  1.4921e-01],\n",
       "         ...,\n",
       "         [-3.8638e-01,  6.8216e-03,  1.1716e+00,  ...,  3.7961e-03,\n",
       "           1.5180e-02, -6.4815e-02],\n",
       "         [-3.6643e-01,  1.9216e-01,  9.5022e-01,  ...,  3.5738e-02,\n",
       "           2.4607e-02, -5.0703e-02],\n",
       "         [-3.7058e-01,  1.5777e-01,  9.9327e-01,  ...,  3.2743e-02,\n",
       "           2.3196e-02, -5.3202e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-0.5622, -0.7422,  0.5058,  ...,  0.0021, -0.0048, -0.0079],\n",
       "         [-0.4243, -1.3138, -0.4748,  ..., -0.0158, -0.0142, -0.0091],\n",
       "         [-0.6314, -1.0481,  0.1599,  ..., -0.7984, -0.4753,  0.0877],\n",
       "         ...,\n",
       "         [-0.5163, -0.8530, -0.5250,  ..., -0.0645, -0.0918, -0.0815],\n",
       "         [-0.5026, -0.9035, -0.4102,  ..., -0.0532, -0.0659, -0.0674],\n",
       "         [-0.5031, -0.8960, -0.4418,  ..., -0.0517, -0.0685, -0.0695]],\n",
       "\n",
       "        [[-0.5622, -0.7422,  0.5058,  ...,  0.0021, -0.0048, -0.0079],\n",
       "         [-0.4243, -1.3138, -0.4748,  ..., -0.0158, -0.0142, -0.0091],\n",
       "         [-0.6314, -1.0481,  0.1599,  ..., -0.7984, -0.4753,  0.0877],\n",
       "         ...,\n",
       "         [-0.5163, -0.8530, -0.5250,  ..., -0.0645, -0.0918, -0.0815],\n",
       "         [-0.5026, -0.9035, -0.4102,  ..., -0.0532, -0.0659, -0.0674],\n",
       "         [-0.5031, -0.8960, -0.4418,  ..., -0.0517, -0.0685, -0.0695]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[ 5.7136e+00, -8.2032e-01, -3.9304e-01,  ..., -1.1311e-02,\n",
       "           1.7105e-03,  7.0484e-03],\n",
       "         [ 5.3372e+00, -1.3956e+00, -5.6341e-01,  ..., -6.2116e-02,\n",
       "           2.0167e-02,  3.3046e-02],\n",
       "         [ 2.5045e+00, -1.7088e+00, -5.2664e-01,  ..., -2.2204e-01,\n",
       "          -1.2476e-01,  4.0192e-01],\n",
       "         ...,\n",
       "         [ 4.5087e+00, -7.1806e-01, -1.5183e+00,  ...,  8.8235e-02,\n",
       "           1.3539e-01,  5.7654e-02],\n",
       "         [ 4.5778e+00, -7.8572e-01, -1.5441e+00,  ...,  3.7439e-02,\n",
       "           1.2450e-01,  7.5671e-02],\n",
       "         [ 4.5537e+00, -7.7147e-01, -1.5494e+00,  ...,  4.6733e-02,\n",
       "           1.2697e-01,  6.8969e-02]],\n",
       "\n",
       "        [[ 5.7136e+00, -8.2032e-01, -3.9304e-01,  ..., -1.1311e-02,\n",
       "           1.7105e-03,  7.0484e-03],\n",
       "         [ 5.3372e+00, -1.3956e+00, -5.6341e-01,  ..., -6.2116e-02,\n",
       "           2.0167e-02,  3.3046e-02],\n",
       "         [ 2.5045e+00, -1.7088e+00, -5.2664e-01,  ..., -2.2204e-01,\n",
       "          -1.2476e-01,  4.0192e-01],\n",
       "         ...,\n",
       "         [ 4.5087e+00, -7.1806e-01, -1.5183e+00,  ...,  8.8235e-02,\n",
       "           1.3539e-01,  5.7654e-02],\n",
       "         [ 4.5778e+00, -7.8572e-01, -1.5441e+00,  ...,  3.7439e-02,\n",
       "           1.2450e-01,  7.5671e-02],\n",
       "         [ 4.5537e+00, -7.7147e-01, -1.5494e+00,  ...,  4.6733e-02,\n",
       "           1.2697e-01,  6.8969e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-2.3553e-01,  1.2579e-01, -1.2001e+01,  ...,  6.5018e-03,\n",
       "          -6.4198e-03, -9.4580e-03],\n",
       "         [-2.3702e-01, -2.6702e-01, -1.0936e+01,  ...,  3.7522e-02,\n",
       "          -5.5591e-02,  1.2924e-03],\n",
       "         [-2.0589e+00, -1.6367e+00,  1.8181e+00,  ..., -6.4346e-01,\n",
       "          -1.1491e-01,  2.6585e-01],\n",
       "         ...,\n",
       "         [ 2.6917e-01, -9.3130e-01, -8.4238e+00,  ..., -5.2644e-02,\n",
       "           8.6067e-02, -3.7943e-02],\n",
       "         [ 1.2666e-01, -8.6620e-01, -9.1283e+00,  ..., -3.8396e-02,\n",
       "           1.1616e-01, -6.5991e-02],\n",
       "         [ 1.4615e-01, -8.8329e-01, -8.9691e+00,  ..., -4.0819e-02,\n",
       "           1.1167e-01, -5.8693e-02]],\n",
       "\n",
       "        [[-2.3553e-01,  1.2579e-01, -1.2001e+01,  ...,  6.5018e-03,\n",
       "          -6.4198e-03, -9.4580e-03],\n",
       "         [-2.3702e-01, -2.6702e-01, -1.0936e+01,  ...,  3.7522e-02,\n",
       "          -5.5591e-02,  1.2924e-03],\n",
       "         [-2.0589e+00, -1.6367e+00,  1.8181e+00,  ..., -6.4346e-01,\n",
       "          -1.1491e-01,  2.6585e-01],\n",
       "         ...,\n",
       "         [ 2.6917e-01, -9.3130e-01, -8.4238e+00,  ..., -5.2644e-02,\n",
       "           8.6067e-02, -3.7943e-02],\n",
       "         [ 1.2666e-01, -8.6620e-01, -9.1283e+00,  ..., -3.8396e-02,\n",
       "           1.1616e-01, -6.5991e-02],\n",
       "         [ 1.4615e-01, -8.8329e-01, -8.9691e+00,  ..., -4.0819e-02,\n",
       "           1.1167e-01, -5.8693e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 0.7006,  0.2501, -0.3630,  ...,  0.0016, -0.0047, -0.0179],\n",
       "         [ 0.2655,  0.0184, -0.1176,  ...,  0.0896,  0.0877, -0.0807],\n",
       "         [ 0.3588,  0.6341,  0.9855,  ...,  0.3494,  1.2280, -0.2983],\n",
       "         ...,\n",
       "         [ 1.4226, -0.3198,  0.1482,  ..., -0.1035, -0.1588, -0.1308],\n",
       "         [ 1.3238, -0.1048,  0.1728,  ..., -0.0915, -0.1807, -0.0963],\n",
       "         [ 1.3470, -0.1467,  0.1728,  ..., -0.0928, -0.1736, -0.1013]],\n",
       "\n",
       "        [[ 0.7006,  0.2501, -0.3630,  ...,  0.0016, -0.0047, -0.0179],\n",
       "         [ 0.2655,  0.0184, -0.1176,  ...,  0.0896,  0.0877, -0.0807],\n",
       "         [ 0.3588,  0.6341,  0.9855,  ...,  0.3494,  1.2280, -0.2983],\n",
       "         ...,\n",
       "         [ 1.4226, -0.3198,  0.1482,  ..., -0.1035, -0.1588, -0.1308],\n",
       "         [ 1.3238, -0.1048,  0.1728,  ..., -0.0915, -0.1807, -0.0963],\n",
       "         [ 1.3470, -0.1467,  0.1728,  ..., -0.0928, -0.1736, -0.1013]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[ 8.6827e-02,  2.0693e-01,  7.8918e-01,  ...,  2.3905e-03,\n",
       "          -3.0962e-03, -9.0752e-03],\n",
       "         [-2.3433e-01, -1.1022e-01,  7.6924e-01,  ..., -4.3800e-03,\n",
       "          -2.4151e-02, -1.1585e-01],\n",
       "         [-1.2163e+00, -8.0190e-01,  2.9366e-02,  ..., -1.7329e-01,\n",
       "          -2.6999e-01, -5.7095e-01],\n",
       "         ...,\n",
       "         [-4.1077e-01,  4.6011e-01,  5.2381e-04,  ...,  1.9895e-01,\n",
       "          -3.4378e-02, -3.7327e-02],\n",
       "         [-3.0548e-01,  5.5858e-01,  3.1341e-02,  ...,  1.3973e-01,\n",
       "          -2.1036e-02, -1.8180e-02],\n",
       "         [-3.2082e-01,  5.4172e-01,  1.5318e-02,  ...,  1.4893e-01,\n",
       "          -2.3805e-02, -2.2109e-02]],\n",
       "\n",
       "        [[ 8.6827e-02,  2.0693e-01,  7.8918e-01,  ...,  2.3905e-03,\n",
       "          -3.0962e-03, -9.0752e-03],\n",
       "         [-2.3433e-01, -1.1022e-01,  7.6924e-01,  ..., -4.3800e-03,\n",
       "          -2.4151e-02, -1.1585e-01],\n",
       "         [-1.2163e+00, -8.0190e-01,  2.9366e-02,  ..., -1.7329e-01,\n",
       "          -2.6999e-01, -5.7095e-01],\n",
       "         ...,\n",
       "         [-4.1077e-01,  4.6011e-01,  5.2381e-04,  ...,  1.9895e-01,\n",
       "          -3.4378e-02, -3.7327e-02],\n",
       "         [-3.0548e-01,  5.5858e-01,  3.1341e-02,  ...,  1.3973e-01,\n",
       "          -2.1036e-02, -1.8180e-02],\n",
       "         [-3.2082e-01,  5.4172e-01,  1.5318e-02,  ...,  1.4893e-01,\n",
       "          -2.3805e-02, -2.2109e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 1.4355e-02, -2.2981e+00, -6.2738e-01,  ...,  2.0634e-02,\n",
       "           1.6332e-03,  3.2057e-03],\n",
       "         [ 4.8852e-02, -2.3465e+00, -4.2947e-01,  ...,  2.9417e-02,\n",
       "           4.0699e-02, -2.5526e-03],\n",
       "         [ 4.5777e-01, -2.6286e+00,  5.8566e-01,  ...,  1.1075e-01,\n",
       "           1.1099e-01, -3.1270e-02],\n",
       "         ...,\n",
       "         [ 9.7823e-01, -2.3758e+00,  6.7221e-01,  ...,  6.3761e-02,\n",
       "           2.5714e-01, -5.1080e-02],\n",
       "         [ 8.8745e-01, -2.4099e+00,  5.0146e-01,  ...,  9.4123e-02,\n",
       "           1.4607e-01, -6.5078e-02],\n",
       "         [ 9.0090e-01, -2.4056e+00,  5.4094e-01,  ...,  8.6660e-02,\n",
       "           1.6657e-01, -6.1482e-02]],\n",
       "\n",
       "        [[ 1.4355e-02, -2.2981e+00, -6.2738e-01,  ...,  2.0634e-02,\n",
       "           1.6332e-03,  3.2057e-03],\n",
       "         [ 4.8852e-02, -2.3465e+00, -4.2947e-01,  ...,  2.9417e-02,\n",
       "           4.0699e-02, -2.5526e-03],\n",
       "         [ 4.5777e-01, -2.6286e+00,  5.8566e-01,  ...,  1.1075e-01,\n",
       "           1.1099e-01, -3.1270e-02],\n",
       "         ...,\n",
       "         [ 9.7823e-01, -2.3758e+00,  6.7221e-01,  ...,  6.3761e-02,\n",
       "           2.5714e-01, -5.1080e-02],\n",
       "         [ 8.8745e-01, -2.4099e+00,  5.0146e-01,  ...,  9.4123e-02,\n",
       "           1.4607e-01, -6.5078e-02],\n",
       "         [ 9.0090e-01, -2.4056e+00,  5.4094e-01,  ...,  8.6660e-02,\n",
       "           1.6657e-01, -6.1482e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-1.6050,  0.6468,  1.4113,  ..., -0.0139,  0.0139, -0.0031],\n",
       "         [-0.9409,  0.8757,  1.1983,  ..., -0.1247,  0.0211, -0.1697],\n",
       "         [-0.0213,  1.0842,  0.9000,  ..., -0.8183, -0.3787, -0.9417],\n",
       "         ...,\n",
       "         [-1.5430,  1.0543,  1.2081,  ..., -0.0765, -0.0049, -0.1624],\n",
       "         [-1.6867,  0.9108,  1.2231,  ..., -0.0908,  0.0846, -0.0897],\n",
       "         [-1.6616,  0.9390,  1.2126,  ..., -0.0892,  0.0655, -0.1051]],\n",
       "\n",
       "        [[-1.6050,  0.6468,  1.4113,  ..., -0.0139,  0.0139, -0.0031],\n",
       "         [-0.9409,  0.8757,  1.1983,  ..., -0.1247,  0.0211, -0.1697],\n",
       "         [-0.0213,  1.0842,  0.9000,  ..., -0.8183, -0.3787, -0.9417],\n",
       "         ...,\n",
       "         [-1.5430,  1.0543,  1.2081,  ..., -0.0765, -0.0049, -0.1624],\n",
       "         [-1.6867,  0.9108,  1.2231,  ..., -0.0908,  0.0846, -0.0897],\n",
       "         [-1.6616,  0.9390,  1.2126,  ..., -0.0892,  0.0655, -0.1051]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[ 0.2831,  0.0763, -0.8881,  ...,  0.0148, -0.0040, -0.0069],\n",
       "         [-0.0752,  0.5652, -0.4619,  ...,  0.0397, -0.0319, -0.0780],\n",
       "         [ 0.2907,  1.6939, -0.7351,  ...,  0.2865, -0.0290, -0.3560],\n",
       "         ...,\n",
       "         [ 0.4473,  1.1511, -0.2738,  ...,  0.1692, -0.2151, -0.1181],\n",
       "         [ 0.5602,  0.9819, -0.3984,  ...,  0.1355, -0.1820, -0.0831],\n",
       "         [ 0.5399,  1.0210, -0.3763,  ...,  0.1411, -0.1869, -0.0904]],\n",
       "\n",
       "        [[ 0.2831,  0.0763, -0.8881,  ...,  0.0148, -0.0040, -0.0069],\n",
       "         [-0.0752,  0.5652, -0.4619,  ...,  0.0397, -0.0319, -0.0780],\n",
       "         [ 0.2907,  1.6939, -0.7351,  ...,  0.2865, -0.0290, -0.3560],\n",
       "         ...,\n",
       "         [ 0.4473,  1.1511, -0.2738,  ...,  0.1692, -0.2151, -0.1181],\n",
       "         [ 0.5602,  0.9819, -0.3984,  ...,  0.1355, -0.1820, -0.0831],\n",
       "         [ 0.5399,  1.0210, -0.3763,  ...,  0.1411, -0.1869, -0.0904]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[-4.2512e-01,  6.2980e-01,  5.4961e-01,  ...,  2.9934e-03,\n",
       "           6.2663e-03, -2.4759e-04],\n",
       "         [-3.4383e-01,  4.5943e-01,  5.2571e-01,  ...,  1.1457e-02,\n",
       "           2.8390e-02,  4.4566e-02],\n",
       "         [-4.6844e-01,  1.2173e+00,  7.6864e-01,  ...,  2.9253e-01,\n",
       "          -9.5842e-03,  3.1878e-01],\n",
       "         ...,\n",
       "         [-1.1659e+00,  1.7437e+00, -1.8870e-01,  ...,  4.8204e-02,\n",
       "           9.2166e-02, -3.1037e-01],\n",
       "         [-1.0839e+00,  1.6403e+00, -2.2542e-01,  ..., -2.3465e-03,\n",
       "           8.7315e-02, -3.0638e-01],\n",
       "         [-1.1049e+00,  1.6638e+00, -2.2854e-01,  ...,  9.8325e-03,\n",
       "           8.8685e-02, -3.0657e-01]],\n",
       "\n",
       "        [[-4.2512e-01,  6.2980e-01,  5.4961e-01,  ...,  2.9934e-03,\n",
       "           6.2663e-03, -2.4759e-04],\n",
       "         [-3.4383e-01,  4.5943e-01,  5.2571e-01,  ...,  1.1457e-02,\n",
       "           2.8390e-02,  4.4566e-02],\n",
       "         [-4.6844e-01,  1.2173e+00,  7.6864e-01,  ...,  2.9253e-01,\n",
       "          -9.5842e-03,  3.1878e-01],\n",
       "         ...,\n",
       "         [-1.1659e+00,  1.7437e+00, -1.8870e-01,  ...,  4.8204e-02,\n",
       "           9.2166e-02, -3.1037e-01],\n",
       "         [-1.0839e+00,  1.6403e+00, -2.2542e-01,  ..., -2.3465e-03,\n",
       "           8.7315e-02, -3.0638e-01],\n",
       "         [-1.1049e+00,  1.6638e+00, -2.2854e-01,  ...,  9.8325e-03,\n",
       "           8.8685e-02, -3.0657e-01]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-8.3341e-02, -1.2366e+00,  7.2135e-02,  ..., -1.4518e-03,\n",
       "          -1.0918e-02,  4.5290e-03],\n",
       "         [-8.1522e-02, -1.5800e+00,  1.5391e-01,  ..., -6.8305e-04,\n",
       "          -1.5490e-02, -2.0076e-02],\n",
       "         [ 4.3746e-01, -2.6702e+00,  5.8157e-01,  ..., -1.1388e-01,\n",
       "          -1.9423e-01,  7.4119e-02],\n",
       "         ...,\n",
       "         [ 1.0485e+00, -2.6656e+00,  1.2165e+00,  ..., -8.3527e-04,\n",
       "          -1.4438e-01, -6.6880e-02],\n",
       "         [ 9.9765e-01, -2.5056e+00,  1.1283e+00,  ...,  1.0562e-03,\n",
       "          -1.3718e-01, -7.2664e-02],\n",
       "         [ 1.0124e+00, -2.5454e+00,  1.1647e+00,  ..., -1.3229e-03,\n",
       "          -1.3543e-01, -7.2035e-02]],\n",
       "\n",
       "        [[-8.3341e-02, -1.2366e+00,  7.2135e-02,  ..., -1.4518e-03,\n",
       "          -1.0918e-02,  4.5290e-03],\n",
       "         [-8.1522e-02, -1.5800e+00,  1.5391e-01,  ..., -6.8305e-04,\n",
       "          -1.5490e-02, -2.0076e-02],\n",
       "         [ 4.3746e-01, -2.6702e+00,  5.8157e-01,  ..., -1.1388e-01,\n",
       "          -1.9423e-01,  7.4119e-02],\n",
       "         ...,\n",
       "         [ 1.0485e+00, -2.6656e+00,  1.2165e+00,  ..., -8.3527e-04,\n",
       "          -1.4438e-01, -6.6880e-02],\n",
       "         [ 9.9765e-01, -2.5056e+00,  1.1283e+00,  ...,  1.0562e-03,\n",
       "          -1.3718e-01, -7.2664e-02],\n",
       "         [ 1.0124e+00, -2.5454e+00,  1.1647e+00,  ..., -1.3229e-03,\n",
       "          -1.3543e-01, -7.2035e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 0.2428, -0.9363, -0.0103,  ..., -0.0176,  0.0159,  0.0037],\n",
       "         [ 0.3610, -1.3677, -0.4238,  ..., -0.0272,  0.0105,  0.0040],\n",
       "         [ 1.2300, -2.3854, -0.7285,  ..., -0.0651, -0.3294, -0.1772],\n",
       "         ...,\n",
       "         [ 0.9510, -1.5131,  0.5023,  ...,  0.0030, -0.0088,  0.0658],\n",
       "         [ 0.9096, -1.4281,  0.5117,  ...,  0.0183,  0.0099,  0.0441],\n",
       "         [ 0.9264, -1.4484,  0.5076,  ...,  0.0132,  0.0073,  0.0487]],\n",
       "\n",
       "        [[ 0.2428, -0.9363, -0.0103,  ..., -0.0176,  0.0159,  0.0037],\n",
       "         [ 0.3610, -1.3677, -0.4238,  ..., -0.0272,  0.0105,  0.0040],\n",
       "         [ 1.2300, -2.3854, -0.7285,  ..., -0.0651, -0.3294, -0.1772],\n",
       "         ...,\n",
       "         [ 0.9510, -1.5131,  0.5023,  ...,  0.0030, -0.0088,  0.0658],\n",
       "         [ 0.9096, -1.4281,  0.5117,  ...,  0.0183,  0.0099,  0.0441],\n",
       "         [ 0.9264, -1.4484,  0.5076,  ...,  0.0132,  0.0073,  0.0487]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[ 0.1602, -0.3078,  0.9053,  ...,  0.0104, -0.0060, -0.0132],\n",
       "         [ 0.0850,  0.0261,  1.0848,  ...,  0.0371, -0.0338, -0.0246],\n",
       "         [ 0.4404,  1.0856,  2.5081,  ..., -0.2696,  0.3834, -0.0371],\n",
       "         ...,\n",
       "         [-0.0663, -1.4432,  0.5905,  ..., -0.1678,  0.1062,  0.1015],\n",
       "         [-0.1076, -1.4268,  0.5510,  ..., -0.1319,  0.0832,  0.0236],\n",
       "         [-0.1104, -1.4474,  0.5568,  ..., -0.1381,  0.0880,  0.0390]],\n",
       "\n",
       "        [[ 0.1602, -0.3078,  0.9053,  ...,  0.0104, -0.0060, -0.0132],\n",
       "         [ 0.0850,  0.0261,  1.0848,  ...,  0.0371, -0.0338, -0.0246],\n",
       "         [ 0.4404,  1.0856,  2.5081,  ..., -0.2696,  0.3834, -0.0371],\n",
       "         ...,\n",
       "         [-0.0663, -1.4432,  0.5905,  ..., -0.1678,  0.1062,  0.1015],\n",
       "         [-0.1076, -1.4268,  0.5510,  ..., -0.1319,  0.0832,  0.0236],\n",
       "         [-0.1104, -1.4474,  0.5568,  ..., -0.1381,  0.0880,  0.0390]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[ 2.8692e-01,  2.2360e+00, -9.3691e-02,  ...,  8.0386e-04,\n",
       "          -3.7215e-03,  1.0348e-02],\n",
       "         [-3.1723e-01,  2.2748e+00,  3.2112e-01,  ..., -1.7070e-03,\n",
       "           2.6602e-02,  3.3084e-02],\n",
       "         [-2.0635e+00,  1.7304e+00,  1.4690e+00,  ...,  7.2480e-02,\n",
       "          -6.5295e-02, -1.0092e-01],\n",
       "         ...,\n",
       "         [-5.3931e-01,  2.7332e+00, -7.2082e-01,  ..., -2.0398e-02,\n",
       "          -6.8196e-02, -4.1516e-02],\n",
       "         [-5.2623e-01,  2.7670e+00, -7.5467e-01,  ..., -7.9395e-02,\n",
       "          -5.2203e-02, -1.2933e-02],\n",
       "         [-5.3720e-01,  2.7694e+00, -7.5701e-01,  ..., -6.5885e-02,\n",
       "          -5.4816e-02, -2.0608e-02]],\n",
       "\n",
       "        [[ 2.8692e-01,  2.2360e+00, -9.3691e-02,  ...,  8.0386e-04,\n",
       "          -3.7215e-03,  1.0348e-02],\n",
       "         [-3.1723e-01,  2.2748e+00,  3.2112e-01,  ..., -1.7070e-03,\n",
       "           2.6602e-02,  3.3084e-02],\n",
       "         [-2.0635e+00,  1.7304e+00,  1.4690e+00,  ...,  7.2480e-02,\n",
       "          -6.5295e-02, -1.0092e-01],\n",
       "         ...,\n",
       "         [-5.3931e-01,  2.7332e+00, -7.2082e-01,  ..., -2.0398e-02,\n",
       "          -6.8196e-02, -4.1516e-02],\n",
       "         [-5.2623e-01,  2.7670e+00, -7.5467e-01,  ..., -7.9395e-02,\n",
       "          -5.2203e-02, -1.2933e-02],\n",
       "         [-5.3720e-01,  2.7694e+00, -7.5701e-01,  ..., -6.5885e-02,\n",
       "          -5.4816e-02, -2.0608e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-5.6502e-02, -3.6418e+00,  4.0255e+00,  ..., -5.5444e-02,\n",
       "          -1.0575e-02,  8.2511e-03],\n",
       "         [-2.0961e-01, -3.1739e+00,  3.8105e+00,  ..., -1.1371e-01,\n",
       "          -6.3384e-02, -3.0331e-02],\n",
       "         [ 1.5885e-01,  2.5688e+00, -3.7474e+00,  ...,  5.9510e-01,\n",
       "           3.0412e-01, -1.4890e-01],\n",
       "         ...,\n",
       "         [ 1.0269e-01, -1.1565e+00,  2.0142e+00,  ...,  2.0871e-02,\n",
       "           6.3975e-02,  4.2149e-02],\n",
       "         [ 4.9200e-02, -1.4023e+00,  2.2773e+00,  ...,  2.9211e-03,\n",
       "          -2.4118e-02,  2.3629e-02],\n",
       "         [ 6.3703e-02, -1.3315e+00,  2.2145e+00,  ...,  6.6122e-03,\n",
       "          -7.2994e-03,  2.3087e-02]],\n",
       "\n",
       "        [[-5.6502e-02, -3.6418e+00,  4.0255e+00,  ..., -5.5444e-02,\n",
       "          -1.0575e-02,  8.2511e-03],\n",
       "         [-2.0961e-01, -3.1739e+00,  3.8105e+00,  ..., -1.1371e-01,\n",
       "          -6.3384e-02, -3.0331e-02],\n",
       "         [ 1.5885e-01,  2.5688e+00, -3.7474e+00,  ...,  5.9510e-01,\n",
       "           3.0412e-01, -1.4890e-01],\n",
       "         ...,\n",
       "         [ 1.0269e-01, -1.1565e+00,  2.0142e+00,  ...,  2.0871e-02,\n",
       "           6.3975e-02,  4.2149e-02],\n",
       "         [ 4.9200e-02, -1.4023e+00,  2.2773e+00,  ...,  2.9211e-03,\n",
       "          -2.4118e-02,  2.3629e-02],\n",
       "         [ 6.3703e-02, -1.3315e+00,  2.2145e+00,  ...,  6.6122e-03,\n",
       "          -7.2994e-03,  2.3087e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 0.6121, -0.3144, -0.2049,  ...,  0.0086, -0.0143,  0.0214],\n",
       "         [ 0.4800, -0.4675,  0.2443,  ...,  0.0397, -0.0336,  0.0430],\n",
       "         [ 0.2454,  1.9411,  1.5583,  ...,  0.4108, -0.1878, -0.5767],\n",
       "         ...,\n",
       "         [ 0.5343, -0.4406,  0.2404,  ...,  0.1054, -0.1233,  0.0060],\n",
       "         [ 0.6114, -0.5358,  0.1426,  ...,  0.1090, -0.0697,  0.0848],\n",
       "         [ 0.5958, -0.5142,  0.1645,  ...,  0.1055, -0.0803,  0.0727]],\n",
       "\n",
       "        [[ 0.6121, -0.3144, -0.2049,  ...,  0.0086, -0.0143,  0.0214],\n",
       "         [ 0.4800, -0.4675,  0.2443,  ...,  0.0397, -0.0336,  0.0430],\n",
       "         [ 0.2454,  1.9411,  1.5583,  ...,  0.4108, -0.1878, -0.5767],\n",
       "         ...,\n",
       "         [ 0.5343, -0.4406,  0.2404,  ...,  0.1054, -0.1233,  0.0060],\n",
       "         [ 0.6114, -0.5358,  0.1426,  ...,  0.1090, -0.0697,  0.0848],\n",
       "         [ 0.5958, -0.5142,  0.1645,  ...,  0.1055, -0.0803,  0.0727]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[ 6.3318e-01,  1.1906e+00, -4.4554e-01,  ...,  3.4062e-03,\n",
       "           7.1779e-03, -1.2037e-02],\n",
       "         [ 8.2109e-01,  1.2219e+00, -2.3280e-01,  ...,  4.0988e-02,\n",
       "          -1.5868e-03, -5.8362e-03],\n",
       "         [ 1.2552e+00,  1.6570e+00,  1.3484e+00,  ...,  4.0102e-01,\n",
       "          -1.7461e-01,  6.3421e-01],\n",
       "         ...,\n",
       "         [ 9.7931e-01,  7.5347e-01, -5.5574e-01,  ...,  8.1629e-02,\n",
       "          -2.4071e-02, -1.5966e-02],\n",
       "         [ 1.0080e+00,  8.8066e-01, -5.2756e-01,  ...,  1.1048e-01,\n",
       "          -3.1578e-02, -2.5638e-02],\n",
       "         [ 1.0104e+00,  8.5446e-01, -5.2742e-01,  ...,  1.0273e-01,\n",
       "          -2.8683e-02, -2.2805e-02]],\n",
       "\n",
       "        [[ 6.3318e-01,  1.1906e+00, -4.4554e-01,  ...,  3.4062e-03,\n",
       "           7.1779e-03, -1.2037e-02],\n",
       "         [ 8.2109e-01,  1.2219e+00, -2.3280e-01,  ...,  4.0988e-02,\n",
       "          -1.5868e-03, -5.8362e-03],\n",
       "         [ 1.2552e+00,  1.6570e+00,  1.3484e+00,  ...,  4.0102e-01,\n",
       "          -1.7461e-01,  6.3421e-01],\n",
       "         ...,\n",
       "         [ 9.7931e-01,  7.5347e-01, -5.5574e-01,  ...,  8.1629e-02,\n",
       "          -2.4071e-02, -1.5966e-02],\n",
       "         [ 1.0080e+00,  8.8066e-01, -5.2756e-01,  ...,  1.1048e-01,\n",
       "          -3.1578e-02, -2.5638e-02],\n",
       "         [ 1.0104e+00,  8.5446e-01, -5.2742e-01,  ...,  1.0273e-01,\n",
       "          -2.8683e-02, -2.2805e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-6.0255e-01,  4.2722e-01, -1.4765e-03,  ..., -2.7757e-03,\n",
       "          -2.4809e-02,  1.0315e-02],\n",
       "         [-4.3329e-01, -1.3345e-01, -2.6543e-01,  ..., -2.7679e-02,\n",
       "          -1.0637e-01, -4.6045e-02],\n",
       "         [ 9.3898e-01, -1.5782e+00, -1.2742e+00,  ..., -4.4190e-01,\n",
       "           3.1740e-02, -1.3111e+00],\n",
       "         ...,\n",
       "         [-1.9178e+00,  6.9574e-01, -5.5657e-01,  ...,  2.5358e-01,\n",
       "          -2.3271e-01, -2.4791e-01],\n",
       "         [-1.8269e+00,  8.4332e-01, -3.9015e-01,  ...,  1.7168e-01,\n",
       "          -2.0076e-01, -1.9536e-01],\n",
       "         [-1.8478e+00,  8.2822e-01, -4.2070e-01,  ...,  1.8387e-01,\n",
       "          -2.0337e-01, -2.0726e-01]],\n",
       "\n",
       "        [[-6.0255e-01,  4.2722e-01, -1.4765e-03,  ..., -2.7757e-03,\n",
       "          -2.4809e-02,  1.0315e-02],\n",
       "         [-4.3329e-01, -1.3345e-01, -2.6543e-01,  ..., -2.7679e-02,\n",
       "          -1.0637e-01, -4.6045e-02],\n",
       "         [ 9.3898e-01, -1.5782e+00, -1.2742e+00,  ..., -4.4190e-01,\n",
       "           3.1740e-02, -1.3111e+00],\n",
       "         ...,\n",
       "         [-1.9178e+00,  6.9574e-01, -5.5657e-01,  ...,  2.5358e-01,\n",
       "          -2.3271e-01, -2.4791e-01],\n",
       "         [-1.8269e+00,  8.4332e-01, -3.9015e-01,  ...,  1.7168e-01,\n",
       "          -2.0076e-01, -1.9536e-01],\n",
       "         [-1.8478e+00,  8.2822e-01, -4.2070e-01,  ...,  1.8387e-01,\n",
       "          -2.0337e-01, -2.0726e-01]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 1.3482e+00,  1.8001e-02, -3.0777e-01,  ..., -3.7531e-03,\n",
       "           2.8509e-03, -9.8704e-04],\n",
       "         [ 9.4253e-01, -2.1858e-01,  3.0440e-02,  ...,  7.7250e-03,\n",
       "           1.5399e-03,  2.0945e-02],\n",
       "         [-1.4809e+00, -8.3099e-01,  1.7252e+00,  ...,  6.2742e-01,\n",
       "           1.7313e-01,  4.5468e-01],\n",
       "         ...,\n",
       "         [-5.9194e-01, -6.5885e-01,  2.6208e-01,  ..., -8.2356e-03,\n",
       "           4.1813e-02, -1.0822e-01],\n",
       "         [-4.7544e-01, -5.5969e-01,  5.3716e-02,  ..., -6.0988e-02,\n",
       "           5.3834e-02, -9.4228e-02],\n",
       "         [-5.2135e-01, -5.8731e-01,  9.6334e-02,  ..., -5.1235e-02,\n",
       "           5.0599e-02, -9.2698e-02]],\n",
       "\n",
       "        [[ 1.3482e+00,  1.8001e-02, -3.0777e-01,  ..., -3.7531e-03,\n",
       "           2.8509e-03, -9.8704e-04],\n",
       "         [ 9.4253e-01, -2.1858e-01,  3.0440e-02,  ...,  7.7250e-03,\n",
       "           1.5399e-03,  2.0945e-02],\n",
       "         [-1.4809e+00, -8.3099e-01,  1.7252e+00,  ...,  6.2742e-01,\n",
       "           1.7313e-01,  4.5468e-01],\n",
       "         ...,\n",
       "         [-5.9194e-01, -6.5885e-01,  2.6208e-01,  ..., -8.2356e-03,\n",
       "           4.1813e-02, -1.0822e-01],\n",
       "         [-4.7544e-01, -5.5969e-01,  5.3716e-02,  ..., -6.0988e-02,\n",
       "           5.3834e-02, -9.4228e-02],\n",
       "         [-5.2135e-01, -5.8731e-01,  9.6334e-02,  ..., -5.1235e-02,\n",
       "           5.0599e-02, -9.2698e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 6.7084e-01,  6.7822e-01,  7.4620e-02,  ...,  3.9225e-04,\n",
       "           4.3947e-03, -8.8105e-03],\n",
       "         [ 5.9983e-01,  3.2783e-01,  1.0746e-01,  ...,  7.1914e-03,\n",
       "          -4.2781e-03,  3.0574e-03],\n",
       "         [-5.7991e-01, -6.8162e-01,  5.1556e-01,  ...,  1.1663e+00,\n",
       "          -2.5300e-01, -3.0547e-01],\n",
       "         ...,\n",
       "         [ 1.0778e+00,  1.0778e+00,  5.7498e-03,  ..., -1.1162e-01,\n",
       "           1.4680e-01,  2.7394e-01],\n",
       "         [ 1.0735e+00,  1.0442e+00, -2.3389e-02,  ..., -8.0974e-02,\n",
       "           1.1441e-01,  2.2738e-01],\n",
       "         [ 1.0733e+00,  1.0591e+00, -1.2974e-02,  ..., -8.7067e-02,\n",
       "           1.2417e-01,  2.3120e-01]],\n",
       "\n",
       "        [[ 6.7084e-01,  6.7822e-01,  7.4620e-02,  ...,  3.9225e-04,\n",
       "           4.3947e-03, -8.8105e-03],\n",
       "         [ 5.9983e-01,  3.2783e-01,  1.0746e-01,  ...,  7.1914e-03,\n",
       "          -4.2781e-03,  3.0574e-03],\n",
       "         [-5.7991e-01, -6.8162e-01,  5.1556e-01,  ...,  1.1663e+00,\n",
       "          -2.5300e-01, -3.0547e-01],\n",
       "         ...,\n",
       "         [ 1.0778e+00,  1.0778e+00,  5.7498e-03,  ..., -1.1162e-01,\n",
       "           1.4680e-01,  2.7394e-01],\n",
       "         [ 1.0735e+00,  1.0442e+00, -2.3389e-02,  ..., -8.0974e-02,\n",
       "           1.1441e-01,  2.2738e-01],\n",
       "         [ 1.0733e+00,  1.0591e+00, -1.2974e-02,  ..., -8.7067e-02,\n",
       "           1.2417e-01,  2.3120e-01]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-0.3893,  0.1110,  0.3961,  ...,  0.0040,  0.0082, -0.0050],\n",
       "         [-0.3866,  0.2058,  0.2415,  ...,  0.0235,  0.0039, -0.0271],\n",
       "         [-1.1077,  1.2185, -0.7113,  ...,  0.2478, -0.7439, -1.2147],\n",
       "         ...,\n",
       "         [-0.2787,  0.2269, -0.5936,  ..., -0.1806,  0.0500, -0.0493],\n",
       "         [-0.2243,  0.1941, -0.5456,  ..., -0.2007,  0.0980, -0.1834],\n",
       "         [-0.2357,  0.2045, -0.5622,  ..., -0.1975,  0.0882, -0.1647]],\n",
       "\n",
       "        [[-0.3893,  0.1110,  0.3961,  ...,  0.0040,  0.0082, -0.0050],\n",
       "         [-0.3866,  0.2058,  0.2415,  ...,  0.0235,  0.0039, -0.0271],\n",
       "         [-1.1077,  1.2185, -0.7113,  ...,  0.2478, -0.7439, -1.2147],\n",
       "         ...,\n",
       "         [-0.2787,  0.2269, -0.5936,  ..., -0.1806,  0.0500, -0.0493],\n",
       "         [-0.2243,  0.1941, -0.5456,  ..., -0.2007,  0.0980, -0.1834],\n",
       "         [-0.2357,  0.2045, -0.5622,  ..., -0.1975,  0.0882, -0.1647]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[ 1.4005, -1.0389, -0.3106,  ..., -0.0235,  0.0031, -0.0064],\n",
       "         [ 1.6935, -1.0268,  0.1181,  ..., -0.0334, -0.0611, -0.0155],\n",
       "         [ 2.1087, -0.5696,  1.2435,  ...,  0.2138,  0.0481,  0.0565],\n",
       "         ...,\n",
       "         [ 1.7921, -1.3774, -0.1114,  ..., -1.1700,  0.0071, -0.2236],\n",
       "         [ 1.7316, -1.3479, -0.2738,  ..., -0.9173,  0.0211, -0.2168],\n",
       "         [ 1.7483, -1.3563, -0.2341,  ..., -0.9581,  0.0164, -0.2216]],\n",
       "\n",
       "        [[ 1.4005, -1.0389, -0.3106,  ..., -0.0235,  0.0031, -0.0064],\n",
       "         [ 1.6935, -1.0268,  0.1181,  ..., -0.0334, -0.0611, -0.0155],\n",
       "         [ 2.1087, -0.5696,  1.2435,  ...,  0.2138,  0.0481,  0.0565],\n",
       "         ...,\n",
       "         [ 1.7921, -1.3774, -0.1114,  ..., -1.1700,  0.0071, -0.2236],\n",
       "         [ 1.7316, -1.3479, -0.2738,  ..., -0.9173,  0.0211, -0.2168],\n",
       "         [ 1.7483, -1.3563, -0.2341,  ..., -0.9581,  0.0164, -0.2216]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[ 1.0810, -0.0784, -0.3081,  ...,  0.0019,  0.0206, -0.0111],\n",
       "         [ 0.6300,  0.0150, -0.5305,  ...,  0.0258,  0.0058, -0.0479],\n",
       "         [-0.0914, -0.5757, -1.2832,  ...,  1.0864,  0.5881, -1.1538],\n",
       "         ...,\n",
       "         [ 0.8336, -1.2123, -1.0984,  ..., -0.3750, -0.2485, -0.0379],\n",
       "         [ 0.8605, -1.0997, -1.2003,  ..., -0.3054, -0.1511,  0.0520],\n",
       "         [ 0.8572, -1.1384, -1.1920,  ..., -0.3169, -0.1595,  0.0359]],\n",
       "\n",
       "        [[ 1.0810, -0.0784, -0.3081,  ...,  0.0019,  0.0206, -0.0111],\n",
       "         [ 0.6300,  0.0150, -0.5305,  ...,  0.0258,  0.0058, -0.0479],\n",
       "         [-0.0914, -0.5757, -1.2832,  ...,  1.0864,  0.5881, -1.1538],\n",
       "         ...,\n",
       "         [ 0.8336, -1.2123, -1.0984,  ..., -0.3750, -0.2485, -0.0379],\n",
       "         [ 0.8605, -1.0997, -1.2003,  ..., -0.3054, -0.1511,  0.0520],\n",
       "         [ 0.8572, -1.1384, -1.1920,  ..., -0.3169, -0.1595,  0.0359]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[-9.5047e-02,  2.6743e-01,  3.8180e-01,  ..., -4.9575e-03,\n",
       "          -5.0412e-03, -2.6525e-03],\n",
       "         [-1.7731e-01,  4.7455e-01,  2.6380e-01,  ...,  1.2526e-02,\n",
       "          -7.4921e-05, -5.3344e-02],\n",
       "         [-8.2041e-01,  1.4575e+00, -3.7486e-01,  ..., -1.5934e-01,\n",
       "           6.2081e-02, -1.1951e+00],\n",
       "         ...,\n",
       "         [-1.0574e+00, -3.0277e-01,  1.0373e+00,  ..., -1.1015e-01,\n",
       "           4.0853e-01, -3.2489e-01],\n",
       "         [-9.6508e-01, -3.1579e-01,  1.0245e+00,  ..., -1.5734e-01,\n",
       "           2.4411e-01, -2.9388e-01],\n",
       "         [-9.9740e-01, -3.1567e-01,  1.0356e+00,  ..., -1.4723e-01,\n",
       "           2.7746e-01, -2.9865e-01]],\n",
       "\n",
       "        [[-9.5047e-02,  2.6743e-01,  3.8180e-01,  ..., -4.9575e-03,\n",
       "          -5.0412e-03, -2.6525e-03],\n",
       "         [-1.7731e-01,  4.7455e-01,  2.6380e-01,  ...,  1.2526e-02,\n",
       "          -7.4921e-05, -5.3344e-02],\n",
       "         [-8.2041e-01,  1.4575e+00, -3.7486e-01,  ..., -1.5934e-01,\n",
       "           6.2081e-02, -1.1951e+00],\n",
       "         ...,\n",
       "         [-1.0574e+00, -3.0277e-01,  1.0373e+00,  ..., -1.1015e-01,\n",
       "           4.0853e-01, -3.2489e-01],\n",
       "         [-9.6508e-01, -3.1579e-01,  1.0245e+00,  ..., -1.5734e-01,\n",
       "           2.4411e-01, -2.9388e-01],\n",
       "         [-9.9740e-01, -3.1567e-01,  1.0356e+00,  ..., -1.4723e-01,\n",
       "           2.7746e-01, -2.9865e-01]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 5.1526e-01,  1.8390e-01, -6.2233e-01,  ...,  1.4619e-03,\n",
       "          -7.3513e-03,  2.1900e-02],\n",
       "         [ 6.4701e-01,  2.0509e-01, -6.7557e-01,  ...,  1.9104e-02,\n",
       "          -9.8118e-02,  4.9691e-02],\n",
       "         [ 2.0564e+00,  6.1688e-01, -6.4220e-01,  ...,  4.1288e-03,\n",
       "          -6.2590e-01, -1.5570e+00],\n",
       "         ...,\n",
       "         [ 1.4453e+00, -4.1786e-01, -9.9775e-01,  ..., -3.1863e-01,\n",
       "           1.6594e-01,  2.2566e-02],\n",
       "         [ 1.1717e+00, -2.4122e-01, -1.0665e+00,  ..., -1.2831e-01,\n",
       "           9.1352e-02, -8.2182e-02],\n",
       "         [ 1.2259e+00, -2.7746e-01, -1.0616e+00,  ..., -1.6504e-01,\n",
       "           1.0346e-01, -5.6631e-02]],\n",
       "\n",
       "        [[ 5.1526e-01,  1.8390e-01, -6.2233e-01,  ...,  1.4619e-03,\n",
       "          -7.3513e-03,  2.1900e-02],\n",
       "         [ 6.4701e-01,  2.0509e-01, -6.7557e-01,  ...,  1.9104e-02,\n",
       "          -9.8118e-02,  4.9691e-02],\n",
       "         [ 2.0564e+00,  6.1688e-01, -6.4220e-01,  ...,  4.1288e-03,\n",
       "          -6.2590e-01, -1.5570e+00],\n",
       "         ...,\n",
       "         [ 1.4453e+00, -4.1786e-01, -9.9775e-01,  ..., -3.1863e-01,\n",
       "           1.6594e-01,  2.2566e-02],\n",
       "         [ 1.1717e+00, -2.4122e-01, -1.0665e+00,  ..., -1.2831e-01,\n",
       "           9.1352e-02, -8.2182e-02],\n",
       "         [ 1.2259e+00, -2.7746e-01, -1.0616e+00,  ..., -1.6504e-01,\n",
       "           1.0346e-01, -5.6631e-02]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 3.7073e-01,  8.2860e-02,  1.1474e-01,  ..., -2.7644e-04,\n",
       "          -1.6738e-04, -3.8445e-03],\n",
       "         [ 6.0925e-01,  1.0035e-01,  1.2443e-01,  ...,  6.0402e-03,\n",
       "          -1.6189e-02,  2.3350e-02],\n",
       "         [ 3.3598e-01,  1.8475e-01, -9.9072e-01,  ..., -5.6254e-01,\n",
       "          -3.0623e-01, -9.3949e-03],\n",
       "         ...,\n",
       "         [ 5.4255e-01,  2.5300e-01, -6.2539e-01,  ..., -5.6245e-01,\n",
       "           1.8374e-01,  6.2334e-01],\n",
       "         [ 3.8853e-01,  1.6788e-01, -5.7458e-01,  ..., -4.4141e-01,\n",
       "           1.9351e-01,  5.3059e-01],\n",
       "         [ 4.1754e-01,  1.8328e-01, -5.8768e-01,  ..., -4.6808e-01,\n",
       "           1.8816e-01,  5.5521e-01]],\n",
       "\n",
       "        [[ 3.7073e-01,  8.2860e-02,  1.1474e-01,  ..., -2.7644e-04,\n",
       "          -1.6738e-04, -3.8445e-03],\n",
       "         [ 6.0925e-01,  1.0035e-01,  1.2443e-01,  ...,  6.0402e-03,\n",
       "          -1.6189e-02,  2.3350e-02],\n",
       "         [ 3.3598e-01,  1.8475e-01, -9.9072e-01,  ..., -5.6254e-01,\n",
       "          -3.0623e-01, -9.3949e-03],\n",
       "         ...,\n",
       "         [ 5.4255e-01,  2.5300e-01, -6.2539e-01,  ..., -5.6245e-01,\n",
       "           1.8374e-01,  6.2334e-01],\n",
       "         [ 3.8853e-01,  1.6788e-01, -5.7458e-01,  ..., -4.4141e-01,\n",
       "           1.9351e-01,  5.3059e-01],\n",
       "         [ 4.1754e-01,  1.8328e-01, -5.8768e-01,  ..., -4.6808e-01,\n",
       "           1.8816e-01,  5.5521e-01]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[-3.9755e-01,  2.1292e-01, -1.9463e-02,  ..., -1.6623e-02,\n",
       "           5.5954e-03, -1.1359e-02],\n",
       "         [-5.1957e-01,  2.5426e-01, -8.7655e-02,  ..., -3.2851e-05,\n",
       "          -2.5330e-02, -3.8283e-02],\n",
       "         [-3.6011e-01, -7.9302e-01,  2.3153e-01,  ...,  8.4015e-01,\n",
       "          -1.2613e+00,  1.5971e+00],\n",
       "         ...,\n",
       "         [ 5.3461e-01, -3.1236e-01, -3.8964e-01,  ...,  1.0609e-01,\n",
       "           4.6689e-01, -1.9825e-01],\n",
       "         [ 4.1028e-01, -1.6917e-01, -3.9749e-01,  ...,  7.3338e-02,\n",
       "           3.8015e-01, -1.7079e-01],\n",
       "         [ 4.3981e-01, -2.0208e-01, -4.0079e-01,  ...,  8.6741e-02,\n",
       "           3.9401e-01, -1.7687e-01]],\n",
       "\n",
       "        [[-3.9755e-01,  2.1292e-01, -1.9463e-02,  ..., -1.6623e-02,\n",
       "           5.5954e-03, -1.1359e-02],\n",
       "         [-5.1957e-01,  2.5426e-01, -8.7655e-02,  ..., -3.2851e-05,\n",
       "          -2.5330e-02, -3.8283e-02],\n",
       "         [-3.6011e-01, -7.9302e-01,  2.3153e-01,  ...,  8.4015e-01,\n",
       "          -1.2613e+00,  1.5971e+00],\n",
       "         ...,\n",
       "         [ 5.3461e-01, -3.1236e-01, -3.8964e-01,  ...,  1.0609e-01,\n",
       "           4.6689e-01, -1.9825e-01],\n",
       "         [ 4.1028e-01, -1.6917e-01, -3.9749e-01,  ...,  7.3338e-02,\n",
       "           3.8015e-01, -1.7079e-01],\n",
       "         [ 4.3981e-01, -2.0208e-01, -4.0079e-01,  ...,  8.6741e-02,\n",
       "           3.9401e-01, -1.7687e-01]]], device='cuda:0',\n",
       "       grad_fn=<SplitWithSizesBackward0>), tensor([[[ 0.6086,  0.2102, -0.3848,  ..., -0.0054, -0.0101, -0.0228],\n",
       "         [ 0.8404,  0.2831, -0.4783,  ..., -0.0510, -0.0501, -0.0473],\n",
       "         [ 0.2605, -1.3995, -0.8057,  ..., -1.2003,  0.2242,  0.1228],\n",
       "         ...,\n",
       "         [ 1.0724,  0.3674,  0.5203,  ..., -0.6289, -0.0645, -0.6523],\n",
       "         [ 0.8882,  0.4514,  0.5408,  ..., -0.5408,  0.0542, -0.5127],\n",
       "         [ 0.9255,  0.4417,  0.5517,  ..., -0.5611,  0.0260, -0.5432]],\n",
       "\n",
       "        [[ 0.6086,  0.2102, -0.3848,  ..., -0.0054, -0.0101, -0.0228],\n",
       "         [ 0.8404,  0.2831, -0.4783,  ..., -0.0510, -0.0501, -0.0473],\n",
       "         [ 0.2605, -1.3995, -0.8057,  ..., -1.2003,  0.2242,  0.1228],\n",
       "         ...,\n",
       "         [ 1.0724,  0.3674,  0.5203,  ..., -0.6289, -0.0645, -0.6523],\n",
       "         [ 0.8882,  0.4514,  0.5408,  ..., -0.5408,  0.0542, -0.5127],\n",
       "         [ 0.9255,  0.4417,  0.5517,  ..., -0.5611,  0.0260, -0.5432]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[-0.7280, -0.0354, -1.0449,  ...,  0.0032, -0.0064,  0.0081],\n",
       "         [-0.1529,  0.1458, -1.0756,  ..., -0.0060,  0.0038,  0.0190],\n",
       "         [ 2.7230, -0.4394, -1.1209,  ..., -0.2793,  1.7300, -0.6060],\n",
       "         ...,\n",
       "         [-0.7913, -0.7876, -1.2927,  ...,  0.7875, -0.2402, -0.3160],\n",
       "         [-0.9112, -0.6244, -1.2466,  ...,  0.7320, -0.1642, -0.2219],\n",
       "         [-0.8970, -0.6623, -1.2550,  ...,  0.7479, -0.1927, -0.2389]],\n",
       "\n",
       "        [[-0.7280, -0.0354, -1.0449,  ...,  0.0032, -0.0064,  0.0081],\n",
       "         [-0.1529,  0.1458, -1.0756,  ..., -0.0060,  0.0038,  0.0190],\n",
       "         [ 2.7230, -0.4394, -1.1209,  ..., -0.2793,  1.7300, -0.6060],\n",
       "         ...,\n",
       "         [-0.7913, -0.7876, -1.2927,  ...,  0.7875, -0.2402, -0.3160],\n",
       "         [-0.9112, -0.6244, -1.2466,  ...,  0.7320, -0.1642, -0.2219],\n",
       "         [-0.8970, -0.6623, -1.2550,  ...,  0.7479, -0.1927, -0.2389]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>), tensor([[[-1.1135, -0.4303, -0.0531,  ..., -0.0093, -0.0064, -0.0034],\n",
       "         [-0.3460, -1.3164,  0.3462,  ..., -0.0637, -0.1674, -0.1130],\n",
       "         [-0.3818,  0.3050, -1.4355,  ..., -0.5381,  1.1446,  0.4267],\n",
       "         ...,\n",
       "         [-0.0353, -1.0919,  0.3621,  ..., -0.8722,  0.3449, -0.3486],\n",
       "         [-0.3053, -1.0365,  0.3621,  ..., -0.6905,  0.2082, -0.1596],\n",
       "         [-0.2374, -1.0607,  0.3633,  ..., -0.7400,  0.2362, -0.2029]],\n",
       "\n",
       "        [[-1.1135, -0.4303, -0.0531,  ..., -0.0093, -0.0064, -0.0034],\n",
       "         [-0.3460, -1.3164,  0.3462,  ..., -0.0637, -0.1674, -0.1130],\n",
       "         [-0.3818,  0.3050, -1.4355,  ..., -0.5381,  1.1446,  0.4267],\n",
       "         ...,\n",
       "         [-0.0353, -1.0919,  0.3621,  ..., -0.8722,  0.3449, -0.3486],\n",
       "         [-0.3053, -1.0365,  0.3621,  ..., -0.6905,  0.2082, -0.1596],\n",
       "         [-0.2374, -1.0607,  0.3633,  ..., -0.7400,  0.2362, -0.2029]]],\n",
       "       device='cuda:0', grad_fn=<SplitWithSizesBackward0>)], hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.ones(batch_size, prefix_size).to(device).long()\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "prefix_size = 50\n",
    "\n",
    "def print_time(batch_size):\n",
    "\n",
    "    start_event = torch.cuda.Event(enable_timing=True)\n",
    "    end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    data = torch.ones(batch_size, prefix_size).to(device).long()\n",
    "\n",
    "    for _ in range(5):\n",
    "        model(data)\n",
    "\n",
    "    start_event.record()\n",
    "    # Your code here\n",
    "    model(data)\n",
    "    end_event.record()\n",
    "\n",
    "    torch.cuda.synchronize()  # Wait for the events to be recorded!\n",
    "    time_taken = start_event.elapsed_time(end_event)  # Time in milliseconds\n",
    "    print(f\"Batch size: {batch_size}, time_taken: {time_taken}, timek_taken per prediction: {time_taken/batch_size}\")\n",
    "    return time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:01<00:08,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 2, time_taken: 272.96868896484375, timek_taken per prediction: 136.48434448242188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:04<00:09,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 4, time_taken: 466.13812255859375, timek_taken per prediction: 116.53453063964844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:09<00:10,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 8, time_taken: 851.6300659179688, timek_taken per prediction: 106.4537582397461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:18<00:11,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 16, time_taken: 1481.82421875, timek_taken per prediction: 92.614013671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:20<00:10,  5.13s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 79.15 GiB total capacity; 77.43 GiB already allocated; 52.31 MiB free; 78.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/code_memorization_starcoder/experiment.ipynb Cell 17\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m batch_sizes \u001b[39m=\u001b[39m [\u001b[39m2\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m16\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m64\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_size \u001b[39min\u001b[39;00m tqdm(batch_sizes):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     print_time(batch_size)\n",
      "\u001b[1;32m/home/daniel/code_memorization_starcoder/experiment.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(batch_size, prefix_size)\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mlong()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     model(data)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m start_event\u001b[39m.\u001b[39mrecord()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B74.235.84.196/home/daniel/code_memorization_starcoder/experiment.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Your code here\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:807\u001b[0m, in \u001b[0;36mGPTBigCodeForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[39mlabels (`torch.Tensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    805\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m--> 807\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m    808\u001b[0m     input_ids,\n\u001b[1;32m    809\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    810\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    811\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[1;32m    812\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    813\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    814\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    815\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    816\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    817\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    818\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    819\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    820\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    821\u001b[0m )\n\u001b[1;32m    822\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    824\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:672\u001b[0m, in \u001b[0;36mGPTBigCodeModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    662\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    663\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    664\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    669\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    670\u001b[0m     )\n\u001b[1;32m    671\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 672\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m    673\u001b[0m         hidden_states,\n\u001b[1;32m    674\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    675\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    676\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    677\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m    678\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_attention_mask,\n\u001b[1;32m    679\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    680\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    681\u001b[0m     )\n\u001b[1;32m    683\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    684\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:353\u001b[0m, in \u001b[0;36mGPTBigCodeBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    351\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m    352\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m--> 353\u001b[0m feed_forward_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(hidden_states)\n\u001b[1;32m    354\u001b[0m \u001b[39m# residual connection\u001b[39;00m\n\u001b[1;32m    355\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/transformers/models/gpt_bigcode/modeling_gpt_bigcode.py:277\u001b[0m, in \u001b[0;36mGPTBigCodeMLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: Optional[Tuple[torch\u001b[39m.\u001b[39mTensor]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    276\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_fc(hidden_states)\n\u001b[0;32m--> 277\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact(hidden_states)\n\u001b[1;32m    278\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_proj(hidden_states)\n\u001b[1;32m    279\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/eval/lib/python3.10/site-packages/transformers/activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mact(\u001b[39minput\u001b[39;49m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 79.15 GiB total capacity; 77.43 GiB already allocated; 52.31 MiB free; 78.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_sizes = [2,4,8,16,32,64]\n",
    "\n",
    "for batch_size in tqdm(batch_sizes):\n",
    "    print_time(batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
